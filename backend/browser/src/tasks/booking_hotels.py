"""
Enhanced Booking.com Hotel Scraper v5.0
========================================

Production-ready scraper with complete data extraction:
- Working reviews extraction with correct selectors
- Full amenities and surroundings extraction
- Proper image validation and deduplication
- Actual Google Maps URLs extraction
- Optimized and maintainable code structure

Version: 5.0 (Production Ready)
Author: Enhanced Implementation
"""

import json
import logging
import re
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from urllib.parse import quote, unquote
import hashlib


class BookingHotelsTask:
    """Production-ready Booking.com hotel scraper with complete data extraction."""
    
    BASE_URL = "https://www.booking.com"
    
    @staticmethod
    async def run(params: Dict[str, Any], logger: logging.Logger, browser, job_output_dir: str = None) -> Dict[str, Any]:
        """Main entry point with enhanced error handling and complete data extraction."""
        try:
            # Validate parameters
            clean_params = BookingHotelsTask._validate_params(params)
            
            # Check scraping mode
            deep_scrape = params.get("deep_scrape", False) or params.get("deep_scrape_enabled", False)
            
            if deep_scrape:
                logger.info("üî• DEEP SCRAPING ENABLED - Extracting complete data with reviews, images, and coordinates")
                scraper = EnhancedScraperEngine(browser, logger)
                hotels = await scraper.scrape_hotels_complete(clean_params)
                extraction_method = "deep_scraping_complete"
            else:
                logger.info("‚ö° QUICK MODE - Extracting essential hotel data")
                scraper = EnhancedScraperEngine(browser, logger)
                hotels = await scraper.scrape_hotels_quick(clean_params)
                extraction_method = "quick_extraction"
            
            # Calculate metrics
            hotels_with_prices = [h for h in hotels if h.get('price_per_night')]
            success_rate = len(hotels_with_prices) / len(hotels) if hotels else 0
            avg_price = sum(h.get('price_per_night', 0) for h in hotels_with_prices) / len(hotels_with_prices) if hotels_with_prices else 0
            
            # Calculate data completeness
            avg_completeness = sum(h.get('data_completeness', 0) for h in hotels) / len(hotels) if hotels else 0
            
            logger.info(f"üèÅ Scraping completed: {len(hotels)} hotels | {success_rate:.1%} with prices | {avg_completeness:.1f}% data completeness")
            
            result = {
                "search_metadata": {
                    "location": clean_params["location"],
                    "check_in": clean_params["check_in"],
                    "check_out": clean_params["check_out"],
                    "nights": clean_params["nights"],
                    "extraction_method": extraction_method,
                    "deep_scrape_enabled": deep_scrape,
                    "total_found": len(hotels),
                    "success_rate": success_rate,
                    "average_price": avg_price,
                    "average_completeness": avg_completeness,
                    "search_completed_at": datetime.now().isoformat()
                },
                "hotels": hotels
            }
            
            # Save data if output directory provided
            if job_output_dir and hotels:
                import os
                output_file = os.path.join(job_output_dir, "hotels_data.json")
                os.makedirs(job_output_dir, exist_ok=True)
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, indent=2, ensure_ascii=False)
                logger.info(f"üíæ Saved complete hotel data to {output_file}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Critical error in scraper: {e}", exc_info=True)
            return {"search_metadata": {"error": str(e)}, "hotels": []}
    
    @staticmethod
    def _validate_params(params: Dict[str, Any]) -> Dict[str, Any]:
        """Validate and normalize input parameters."""
        location = params.get("location", "").strip()
        if not location:
            raise ValueError("Location is required")
        
        # Parse dates
        check_in = params.get("check_in")
        check_out = params.get("check_out")
        
        if isinstance(check_in, str):
            check_in = datetime.fromisoformat(check_in.replace('Z', '+00:00')).date()
        if isinstance(check_out, str):
            check_out = datetime.fromisoformat(check_out.replace('Z', '+00:00')).date()
        
        # Default dates
        if not check_in:
            check_in = (datetime.now() + timedelta(days=1)).date()
        if not check_out:
            check_out = check_in + timedelta(days=3)
        
        return {
            "location": location,
            "check_in": check_in.isoformat(),
            "check_out": check_out.isoformat(),
            "nights": (check_out - check_in).days,
            "adults": max(1, int(params.get("adults", 2))),
            "children": max(0, int(params.get("children", 0))),
            "rooms": max(1, int(params.get("rooms", 1))),
            "max_results": max(1, int(params.get("max_results", 10)))
        }


class EnhancedScraperEngine:
    """Enhanced scraper engine with improved data extraction."""
    
    BASE_URL = "https://www.booking.com"
    
    def __init__(self, browser, logger: logging.Logger):
        self.browser = browser
        self.logger = logger
        self.intercepted_data = {
            "weekend_deals": [],
            "graphql_responses": [],
            "search_results_html": None
        }
        
    async def scrape_hotels_quick(self, params: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Quick extraction with essential data."""
        context = await self._create_browser_context()
        page = await context.new_page()
        
        try:
            # Set up interception
            await self._setup_interception(page)
            
            # Navigate and search
            await page.goto(self.BASE_URL, wait_until="networkidle")
            await self._handle_popups(page)
            await self._perform_search(page, params)
            
            # Wait for data
            await page.wait_for_timeout(10000)
            
            # Store search results HTML for URL extraction
            self.intercepted_data["search_results_html"] = await page.content()
            
            # Parse weekend deals
            hotels = await self._parse_weekend_deals()
            
            # Fix URLs and images
            hotels = await self._fix_hotel_data(page, hotels)
            
            self.logger.info(f"‚úÖ Quick extraction completed: {len(hotels)} hotels")
            return hotels
            
        finally:
            await context.close()
    
    async def scrape_hotels_complete(self, params: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Complete extraction with all details including reviews, coordinates, etc."""
        # Get basic hotels first
        basic_hotels = await self.scrape_hotels_quick(params)
        
        # Limit to max_results
        max_results = params.get("max_results", 10)
        hotels_to_process = basic_hotels[:max_results]
        
        # Enhance each hotel
        enhanced_hotels = []
        
        for i, hotel in enumerate(hotels_to_process, 1):
            try:
                self.logger.info(f"üè® Deep scraping hotel {i}/{len(hotels_to_process)}: {hotel.get('name')}")
                
                # Try to get or generate URL
                if not hotel.get('booking_url'):
                    hotel['booking_url'] = await self._find_hotel_url(hotel, params)
                
                if hotel.get('booking_url'):
                    # Extract comprehensive data
                    enhanced_hotel = await self._extract_complete_hotel_data(hotel, params)
                    enhanced_hotels.append(enhanced_hotel)
                else:
                    self.logger.warning(f"‚ö†Ô∏è Could not find URL for: {hotel.get('name')}")
                    hotel['extraction_error'] = "No booking URL found"
                    enhanced_hotels.append(hotel)
                
                # Delay between requests
                if i < len(hotels_to_process):
                    await asyncio.sleep(2)
                    
            except Exception as e:
                self.logger.error(f"‚ùå Error enhancing hotel {hotel.get('name')}: {e}")
                hotel['extraction_error'] = str(e)
                enhanced_hotels.append(hotel)
        
        self.logger.info(f"üéØ Complete extraction finished: {len(enhanced_hotels)} hotels")
        return enhanced_hotels
    
    async def _find_hotel_url(self, hotel: Dict[str, Any], params: Dict[str, Any]) -> Optional[str]:
        """Find hotel URL using multiple strategies."""
        context = await self._create_browser_context()
        page = await context.new_page()
        
        try:
            # Strategy 1: Search by hotel name
            search_url = f"{self.BASE_URL}/searchresults.html?ss={quote(hotel.get('name', ''))}&checkin={params['check_in']}&checkout={params['check_out']}"
            await page.goto(search_url, wait_until="networkidle", timeout=20000)
            
            # Look for exact match
            hotel_cards = await page.query_selector_all("[data-testid='property-card']")
            for card in hotel_cards[:5]:  # Check first 5 results
                try:
                    title_element = await card.query_selector("[data-testid='title']")
                    if title_element:
                        title = await title_element.text_content()
                        if title and hotel.get('name') in title:
                            link = await card.query_selector("a[href*='/hotel/']")
                            if link:
                                href = await link.get_attribute("href")
                                if href:
                                    url = href.split('?')[0] if '?' in href else href
                                    if not url.startswith("http"):
                                        url = f"https://www.booking.com{url}"
                                    self.logger.info(f"‚úÖ Found URL via search: {url}")
                                    return url
                except:
                    continue
            
            return None
            
        except Exception as e:
            self.logger.debug(f"URL finding error: {e}")
            return None
        finally:
            await context.close()
    
    async def _extract_complete_hotel_data(self, hotel: Dict[str, Any], params: Dict[str, Any]) -> Dict[str, Any]:
        """Extract complete data for a single hotel with improved extraction methods."""
        context = await self._create_browser_context()
        page = await context.new_page()
        
        try:
            enhanced_hotel = hotel.copy()
            hotel_url = hotel.get('booking_url')
            
            if not hotel_url:
                return enhanced_hotel
            
            self.logger.info(f"üåê Navigating to: {hotel_url}")
            
            # Navigate to hotel page with longer timeout
            await page.goto(hotel_url, wait_until="networkidle", timeout=30000)
            await page.wait_for_timeout(5000)  # Increased wait time
            
            # Extract hotel ID from page
            hotel_id = await self._extract_hotel_id_from_page(page)
            if hotel_id:
                enhanced_hotel['hotel_id'] = hotel_id
            
            # 1. Extract Location Coordinates and Google Maps URL
            location_data = await self._extract_location_data(page)
            if location_data:
                enhanced_hotel.update(location_data)
            
            # 2. Extract All Images (high quality) - Improved
            images = await self._extract_all_images_enhanced(page)
            enhanced_hotel['images'] = images
            enhanced_hotel['image_count'] = len(images)
            
            # 3. Extract Reviews - FIXED with correct selectors
            reviews_data = await self._extract_reviews_fixed(page)
            if reviews_data:
                enhanced_hotel['reviews'] = reviews_data['reviews']
                enhanced_hotel['review_count'] = reviews_data['total_count']
                enhanced_hotel['rating_breakdown'] = reviews_data.get('rating_breakdown', {})
            
            # 4. Extract Amenities - IMPROVED
            amenities = await self._extract_amenities_improved(page)
            enhanced_hotel['amenities'] = amenities
            
            # 5. Extract Description
            description = await self._extract_description_improved(page)
            if description:
                enhanced_hotel['description'] = description
            
            # 6. Extract Surroundings - FIXED
            surroundings = await self._extract_surroundings_fixed(page)
            if surroundings:
                enhanced_hotel['surroundings'] = surroundings
            
            # Calculate completeness
            enhanced_hotel['data_completeness'] = self._calculate_completeness(enhanced_hotel)
            enhanced_hotel['scraping_timestamp'] = datetime.now().isoformat()
            
            self.logger.info(
                f"‚úÖ Extracted complete data for {enhanced_hotel.get('name')}: "
                f"{len(images)} images, {len(enhanced_hotel.get('reviews', []))} reviews, "
                f"coordinates: {bool(location_data)}, completeness: {enhanced_hotel['data_completeness']}%"
            )
            
            return enhanced_hotel
            
        except Exception as e:
            self.logger.error(f"‚ùå Error extracting complete data: {e}", exc_info=True)
            hotel['extraction_error'] = str(e)
            return hotel
        finally:
            await context.close()
    
    async def _extract_hotel_id_from_page(self, page) -> Optional[str]:
        """Extract hotel ID from the current page."""
        try:
            # Try multiple methods
            # Method 1: From JavaScript variables
            hotel_id = await page.evaluate("""
                () => {
                    if (window.B && window.B.env && window.B.env.b_hotel_id) {
                        return window.B.env.b_hotel_id;
                    }
                    if (window.booking && window.booking.env && window.booking.env.b_hotel_id) {
                        return window.booking.env.b_hotel_id;
                    }
                    // Try from page source
                    const scripts = document.querySelectorAll('script');
                    for (let script of scripts) {
                        const match = script.textContent.match(/b_hotel_id["\s:]+["']?(\d+)["']?/);
                        if (match) return match[1];
                    }
                    return null;
                }
            """)
            
            if hotel_id:
                return str(hotel_id)
            
            # Method 2: From URL
            url = page.url
            match = re.search(r'hotel_id=(\d+)', url)
            if match:
                return match.group(1)
            
            return None
            
        except Exception as e:
            self.logger.debug(f"Hotel ID extraction error: {e}")
            return None
    
    async def _extract_location_data(self, page) -> Optional[Dict[str, Any]]:
        """Extract location coordinates and actual Google Maps URL."""
        try:
            location_data = {}
            
            # Extract coordinates
            coordinates = await page.evaluate("""
                () => {
                    // Try B.env variables
                    if (window.B && window.B.env) {
                        const env = window.B.env;
                        if (env.b_map_center_latitude && env.b_map_center_longitude) {
                            return {
                                lat: parseFloat(env.b_map_center_latitude),
                                lng: parseFloat(env.b_map_center_longitude)
                            };
                        }
                    }
                    
                    // Try from map container
                    const mapContainer = document.querySelector('#hotel_sidebar_static_map, .bui-map-container, #hotel_address_map');
                    if (mapContainer) {
                        const lat = mapContainer.getAttribute('data-atlas-latlng');
                        if (lat) {
                            const [latitude, longitude] = lat.split(',').map(parseFloat);
                            return { lat: latitude, lng: longitude };
                        }
                    }
                    
                    return null;
                }
            """)
            
            if coordinates:
                location_data['latitude'] = coordinates['lat']
                location_data['longitude'] = coordinates['lng']
            
            # Extract actual Google Maps URL from the page
            google_maps_url = await page.evaluate("""
                () => {
                    // Look for Google Maps links
                    const mapLinks = document.querySelectorAll('a[href*="maps.google"], a[href*="google.com/maps"]');
                    for (let link of mapLinks) {
                        const href = link.href;
                        if (href && (href.includes('maps.google') || href.includes('google.com/maps'))) {
                            return href;
                        }
                    }
                    
                    // Check map container
                    const mapContainer = document.querySelector('.map_static_zoom');
                    if (mapContainer) {
                        const link = mapContainer.querySelector('a');
                        if (link && link.href) return link.href;
                    }
                    
                    return null;
                }
            """)
            
            if google_maps_url:
                location_data['google_maps_url'] = google_maps_url
            elif coordinates:
                # Fallback to generated URL if no actual URL found
                location_data['google_maps_url'] = f"https://www.google.com/maps/search/{coordinates['lat']},{coordinates['lng']}"
            
            return location_data if location_data else None
            
        except Exception as e:
            self.logger.debug(f"Location extraction error: {e}")
            return None
    
    async def _extract_all_images_enhanced(self, page) -> List[str]:
        """Extract all hotel images with better validation and deduplication."""
        images = []
        seen_hashes = set()
        
        try:
            # Try to open photo gallery
            gallery_opened = False
            gallery_selectors = [
                "[data-testid='property-gallery-open-gallery-button']",
                "button[aria-label*='photo']",
                ".bh-photo-grid-item a",
                "a.photo_item",
                "[data-preview-image-layout] button"
            ]
            
            for selector in gallery_selectors:
                try:
                    element = await page.query_selector(selector)
                    if element:
                        await element.click()
                        await page.wait_for_timeout(3000)
                        gallery_opened = True
                        self.logger.debug("‚úÖ Opened photo gallery")
                        break
                except:
                    continue
            
            # Extract images
            image_urls = await page.evaluate("""
                () => {
                    const images = new Set();
                    
                    // Get all image elements
                    const selectors = [
                        '.slick-slide img',
                        '.bh-photo-modal img',
                        '[data-testid="image"] img',
                        '.hp-gallery__item img',
                        '.hp_gallery img',
                        'img[data-highres]',
                        'img.hide'
                    ];
                    
                    selectors.forEach(selector => {
                        document.querySelectorAll(selector).forEach(img => {
                            let src = img.getAttribute('data-highres') || 
                                     img.getAttribute('data-src') || 
                                     img.src;
                            
                            if (src && src.includes('bstatic')) {
                                // Clean and normalize URL
                                if (src.startsWith('//')) src = 'https:' + src;
                                else if (src.startsWith('/')) src = 'https://cf.bstatic.com' + src;
                                
                                // Convert to high quality
                                src = src.replace(/square\d+/, 'max1024x768')
                                        .replace(/max\d+/, 'max1024x768')
                                        .replace(/thumbnail/, 'max1024x768');
                                
                                images.add(src);
                            }
                        });
                    });
                    
                    return Array.from(images);
                }
            """)
            
            # Validate and deduplicate images
            for url in image_urls:
                if url and 'bstatic' in url:
                    # Create a simple hash for deduplication
                    url_hash = hashlib.md5(url.encode()).hexdigest()
                    if url_hash not in seen_hashes:
                        seen_hashes.add(url_hash)
                        images.append(url)
            
            # Close gallery if opened
            if gallery_opened:
                try:
                    await page.keyboard.press('Escape')
                    await page.wait_for_timeout(1000)
                except:
                    pass
            
            return images[:50]  # Limit to 50 images
            
        except Exception as e:
            self.logger.debug(f"Image extraction error: {e}")
            return images[:30] if images else []
    
    async def _extract_reviews_fixed(self, page) -> Optional[Dict[str, Any]]:
        """Extract reviews using the correct selectors from the HTML structure."""
        try:
            reviews = []
            
            # Scroll to reviews section to ensure they're loaded
            await page.evaluate("""
                () => {
                    const reviewSection = document.querySelector('#reviewlist, [data-testid="reviews-section"], .review_list');
                    if (reviewSection) reviewSection.scrollIntoView();
                }
            """)
            await page.wait_for_timeout(2000)
            
            # Extract reviews using the UPDATED correct selectors based on current HTML
            reviews = await page.evaluate("""
                () => {
                    const reviews = [];
                    const reviewCards = document.querySelectorAll('[data-testid="review-card"]');
                    
                    reviewCards.forEach((card, index) => {
                        if (index >= 20) return; // Limit to 20 reviews
                        
                        const review = {};
                        
                        // Extract reviewer name - UPDATED selector
                        const nameEl = card.querySelector('.b08850ce41.f546354b44');
                        if (nameEl) review.reviewer = nameEl.textContent.trim();
                        
                        // Extract review score - UPDATED selector  
                        const scoreEl = card.querySelector('[data-testid="review-score"] .f63b14ab7a.dff2e52086');
                        if (scoreEl) {
                            const scoreText = scoreEl.textContent;
                            const match = scoreText.match(/\\d+\\.?\\d*/);
                            if (match) review.score = parseFloat(match[0]);
                        }
                        
                        // Extract review title - UPDATED selector
                        const titleEl = card.querySelector('[data-testid="review-title"]');
                        if (titleEl) review.title = titleEl.textContent.trim();
                        
                        // Extract positive text - UPDATED selector
                        const positiveEl = card.querySelector('[data-testid="review-positive-text"] .b99b6ef58f');
                        if (positiveEl) review.positive = positiveEl.textContent.trim();
                        
                        // Extract negative text - UPDATED selector
                        const negativeEl = card.querySelector('[data-testid="review-negative-text"] .b99b6ef58f');
                        if (negativeEl) review.negative = negativeEl.textContent.trim();
                        
                        // Extract review date - UPDATED selector
                        const dateEl = card.querySelector('[data-testid="review-date"]');
                        if (dateEl) {
                            const dateText = dateEl.textContent;
                            review.date = dateText.replace('Reviewed:', '').trim();
                        }
                        
                        // Extract room type - UPDATED selector
                        const roomEl = card.querySelector('[data-testid="review-room-name"]');
                        if (roomEl) review.room_type = roomEl.textContent.trim();
                        
                        // Extract traveler type - UPDATED selector
                        const travelerEl = card.querySelector('[data-testid="review-traveler-type"]');
                        if (travelerEl) review.traveler_type = travelerEl.textContent.trim();
                        
                        // Extract country - UPDATED selector
                        const countryEl = card.querySelector('.d838fb5f41.aea5eccb71');
                        if (countryEl) review.country = countryEl.textContent.trim();
                        
                        // Extract stay info
                        const nightsEl = card.querySelector('[data-testid="review-num-nights"]');
                        if (nightsEl) review.nights = nightsEl.textContent.trim();
                        
                        const stayDateEl = card.querySelector('[data-testid="review-stay-date"]');
                        if (stayDateEl) review.stay_date = stayDateEl.textContent.trim();
                        
                        // Only add if we have some content
                        if (review.score || review.positive || review.negative || review.title) {
                            reviews.push(review);
                        }
                    });
                    
                    return reviews;
                }
            """)
            
            # Get total review count - UPDATED selector
            total_count = await page.evaluate("""
                () => {
                    // Look for review count in the review opener element
                    const reviewOpener = document.querySelector('.fff1944c52.fb14de7f14');
                    if (reviewOpener && reviewOpener.textContent.includes('review')) {
                        const text = reviewOpener.textContent;
                        const match = text.match(/\\d[\\d,]*/);
                        if (match) return parseInt(match[0].replace(/,/g, ''));
                    }
                    
                    // Try alternative selectors for review count
                    const countSelectors = [
                        '.reviews_header_count',
                        '[data-testid="reviews-count"]', 
                        '.review_list_header_count',
                        '.bui-review-score__text'
                    ];
                    
                    for (let selector of countSelectors) {
                        const el = document.querySelector(selector);
                        if (el) {
                            const text = el.textContent;
                            const match = text.match(/\\d[\\d,]*/);
                            if (match) return parseInt(match[0].replace(/,/g, ''));
                        }
                    }
                    
                    return 0;
                }
            """)
            
            # Extract rating breakdown - UPDATED to use the correct selectors from the hidden element
            rating_breakdown = await page.evaluate("""
                () => {
                    const breakdown = {};
                    
                    // Look for rating categories in the hidden breakdown tooltip
                    const categories = document.querySelectorAll('#review_list_score_breakdown li');
                    
                    categories.forEach(cat => {
                        const label = cat.querySelector('.review_score_name');
                        const score = cat.querySelector('.review_score_value');
                        
                        if (label && score) {
                            const name = label.textContent.trim();
                            const value = parseFloat(score.textContent);
                            if (name && !isNaN(value)) {
                                breakdown[name] = value;
                            }
                        }
                    });
                    
                    // Fallback: try other possible selectors
                    if (Object.keys(breakdown).length === 0) {
                        const fallbackCategories = document.querySelectorAll('.review_list_score_breakdown li, [data-testid="review-subscore"]');
                        
                        fallbackCategories.forEach(cat => {
                            const label = cat.querySelector('.review_score_name, .c-score-bar__title');
                            const score = cat.querySelector('.review_score_value, .c-score-bar__score');
                            
                            if (label && score) {
                                const name = label.textContent.trim();
                                const value = parseFloat(score.textContent);
                                if (name && !isNaN(value)) {
                                    breakdown[name] = value;
                                }
                            }
                        });
                    }
                    
                    return breakdown;
                }
            """)
            
            if len(reviews) > 0 or len(rating_breakdown) > 0:
                return {
                    'reviews': reviews,
                    'total_count': total_count or len(reviews),
                    'rating_breakdown': rating_breakdown
                }
            
            return None
            
        except Exception as e:
            self.logger.debug(f"Review extraction error: {e}")
            return None
    
    async def _extract_amenities_improved(self, page) -> List[str]:
        """Extract amenities with improved selectors and logic."""
        amenities = set()
        
        try:
            # First, try to expand all amenities
            try:
                show_all_button = await page.query_selector('button:has-text("Show all"), button:has-text("facilities")')
                if show_all_button:
                    await show_all_button.click()
                    await page.wait_for_timeout(2000)
            except:
                pass
            
            # Extract amenities using multiple strategies
            amenities_data = await page.evaluate("""
                () => {
                    const amenities = new Set();
                    
                    // Strategy 1: Property highlights
                    document.querySelectorAll('[data-testid="property-highlights"] li').forEach(el => {
                        const text = el.textContent.trim();
                        if (text) amenities.add(text);
                    });
                    
                    // Strategy 2: Important facilities
                    document.querySelectorAll('.important_facility, .hp-description .important_facility').forEach(el => {
                        const text = el.textContent.trim();
                        if (text) amenities.add(text);
                    });
                    
                    // Strategy 3: Facilities list
                    document.querySelectorAll('.facilitiesChecklist .facilitiesChecklistSection').forEach(section => {
                        section.querySelectorAll('li, .bui-list__item').forEach(item => {
                            const text = item.textContent.trim();
                            if (text && !text.includes('Not included')) amenities.add(text);
                        });
                    });
                    
                    // Strategy 4: Hotel facilities
                    document.querySelectorAll('[data-testid="facility"], .hotel-facilities__item').forEach(el => {
                        const text = el.textContent.trim();
                        if (text) amenities.add(text);
                    });
                    
                    // Strategy 5: Property amenities section
                    document.querySelectorAll('[data-testid="property-amenities-list"] li').forEach(el => {
                        const text = el.textContent.trim();
                        if (text) amenities.add(text);
                    });
                    
                    // Strategy 6: Most popular facilities
                    document.querySelectorAll('.hp_desc_important_facilities li').forEach(el => {
                        const text = el.textContent.trim().replace(/\\n/g, ' ').replace(/\\s+/g, ' ');
                        if (text && text.length > 2) amenities.add(text);
                    });
                    
                    return Array.from(amenities).filter(a => a.length > 2 && a.length < 100);
                }
            """)
            
            return list(amenities_data)[:50]  # Limit to 50 amenities
            
        except Exception as e:
            self.logger.debug(f"Amenities extraction error: {e}")
            return list(amenities)[:30] if amenities else []
    
    async def _extract_description_improved(self, page) -> Optional[str]:
        """Extract hotel description with improved logic."""
        try:
            description = await page.evaluate("""
                () => {
                    // Try multiple selectors
                    const selectors = [
                        '[data-testid="property-description"]',
                        '#property_description_content',
                        '.hp_desc_main_content',
                        '#summary',
                        '.property-description'
                    ];
                    
                    for (let selector of selectors) {
                        const el = document.querySelector(selector);
                        if (el) {
                            const text = el.textContent.trim()
                                .replace(/\\n+/g, ' ')
                                .replace(/\\s+/g, ' ');
                            if (text.length > 50) return text;
                        }
                    }
                    
                    // Try to get from structured data
                    const scripts = document.querySelectorAll('script[type="application/ld+json"]');
                    for (let script of scripts) {
                        try {
                            const data = JSON.parse(script.textContent);
                            if (data.description) return data.description;
                        } catch (e) {}
                    }
                    
                    return null;
                }
            """)
            
            return description[:2000] if description else None  # Limit length
            
        except Exception as e:
            self.logger.debug(f"Description extraction error: {e}")
            return None
    
    async def _extract_surroundings_fixed(self, page) -> Dict[str, List]:
        """Extract surroundings with fixed selectors and logic."""
        surroundings = {
            'landmarks': [],
            'restaurants': [],
            'transport': []
        }
        
        try:
            # Scroll to surroundings section
            await page.evaluate("""
                () => {
                    const section = document.querySelector('.hp-surroundings, [data-component="surroundings"], #distance_section');
                    if (section) section.scrollIntoView();
                }
            """)
            await page.wait_for_timeout(1000)
            
            # Extract surroundings data
            surroundings_data = await page.evaluate("""
                () => {
                    const result = {
                        landmarks: [],
                        restaurants: [],
                        transport: []
                    };
                    
                    // Method 1: Look for distance section
                    const distanceSection = document.querySelector('#distance_section, .hp-surroundings');
                    if (distanceSection) {
                        const items = distanceSection.querySelectorAll('li, .bui-list__item, .hp-poi-list__item');
                        items.forEach(item => {
                            const text = item.textContent.trim();
                            if (!text) return;
                            
                            // Categorize based on content
                            if (text.match(/airport|station|metro|bus|train/i)) {
                                result.transport.push(text);
                            } else if (text.match(/restaurant|cafe|coffee|bar|food|dining/i)) {
                                result.restaurants.push(text);
                            } else if (text.match(/beach|park|museum|mall|center|square/i)) {
                                result.landmarks.push(text);
                            } else {
                                // Default to landmarks for other POIs
                                result.landmarks.push(text);
                            }
                        });
                    }
                    
                    // Method 2: Look for specific surrounding sections
                    const sections = document.querySelectorAll('.hp-poi-content__section');
                    sections.forEach(section => {
                        const title = section.querySelector('.hp-poi-content__section-title');
                        const items = section.querySelectorAll('.hp-poi-content__item');
                        
                        if (!title) return;
                        const sectionTitle = title.textContent.toLowerCase();
                        
                        items.forEach(item => {
                            const name = item.querySelector('.hp-poi-list__item-name');
                            const distance = item.querySelector('.hp-poi-list__item-distance');
                            
                            if (name) {
                                const text = name.textContent + (distance ? ' - ' + distance.textContent : '');
                                
                                if (sectionTitle.includes('transport') || sectionTitle.includes('airport')) {
                                    result.transport.push(text);
                                } else if (sectionTitle.includes('restaurant') || sectionTitle.includes('food')) {
                                    result.restaurants.push(text);
                                } else {
                                    result.landmarks.push(text);
                                }
                            }
                        });
                    });
                    
                    // Method 3: Alternative selectors
                    if (result.landmarks.length === 0 && result.restaurants.length === 0 && result.transport.length === 0) {
                        // Try alternative extraction
                        const surroundingsList = document.querySelectorAll('[data-testid="surroundings-list"] li');
                        surroundingsList.forEach(item => {
                            const text = item.textContent.trim();
                            if (text) result.landmarks.push(text);
                        });
                    }
                    
                    // Limit and clean results
                    result.landmarks = result.landmarks.slice(0, 10).map(t => t.replace(/\\s+/g, ' ').trim());
                    result.restaurants = result.restaurants.slice(0, 10).map(t => t.replace(/\\s+/g, ' ').trim());
                    result.transport = result.transport.slice(0, 10).map(t => t.replace(/\\s+/g, ' ').trim());
                    
                    return result;
                }
            """)
            
            return surroundings_data
            
        except Exception as e:
            self.logger.debug(f"Surroundings extraction error: {e}")
            return surroundings
    
    async def _setup_interception(self, page):
        """Set up request/response interception."""
        async def handle_response(response):
            if "/dml/graphql" in response.url and response.status == 200:
                try:
                    data = await response.json()
                    
                    # Capture weekend deals
                    if "weekendDeals" in str(data):
                        self.intercepted_data["weekend_deals"].append(data)
                        deals = self._extract_weekend_deals_count(data)
                        if deals > 0:
                            self.logger.info(f"‚úÖ Captured weekend deals response with {deals} hotels")
                    
                    # Store all GraphQL responses
                    self.intercepted_data["graphql_responses"].append(data)
                    
                except Exception as e:
                    self.logger.debug(f"Response parsing error: {e}")
        
        page.on("response", handle_response)
    
    async def _parse_weekend_deals(self) -> List[Dict[str, Any]]:
        """Parse weekend deals responses."""
        hotels = []
        
        for response_data in self.intercepted_data["weekend_deals"]:
            try:
                deals = self._get_nested_value(response_data, ["data", "weekendDeals", "weekendDealsProperties"])
                if deals and isinstance(deals, list):
                    for item in deals:
                        hotel = self._parse_hotel_item(item)
                        if hotel:
                            hotels.append(hotel)
                            self.logger.info(f"‚úÖ Parsed: {hotel['name']} - ${hotel.get('price_per_night', 'N/A')} SAR")
            except Exception as e:
                self.logger.debug(f"Weekend deals parsing error: {e}")
        
        return hotels
    
    async def _fix_hotel_data(self, page, hotels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Fix hotel URLs and images."""
        try:
            # Get all hotel links from the current page
            hotel_links = await page.query_selector_all("a[href*='/hotel/']")
            url_map = {}
            
            for link in hotel_links:
                try:
                    href = await link.get_attribute("href")
                    if href and "/hotel/" in href:
                        # Extract clean URL
                        clean_url = href.split('?')[0] if '?' in href else href
                        if not clean_url.startswith("http"):
                            clean_url = f"https://www.booking.com{clean_url}"
                        
                        # Try to get hotel name
                        parent = await link.query_selector("xpath=..")
                        title_element = await parent.query_selector("[data-testid='title']") if parent else None
                        if not title_element:
                            title_element = await link.query_selector("[data-testid='title']")
                        
                        if title_element:
                            title = await title_element.text_content()
                            if title:
                                url_map[title.strip()] = clean_url
                        
                except Exception as e:
                    self.logger.debug(f"Link extraction error: {e}")
                    continue
            
            # Fix each hotel
            for hotel in hotels:
                # Fix URL
                hotel_name = hotel.get('name', '')
                if hotel_name and not hotel.get('booking_url'):
                    # Try exact match
                    if hotel_name in url_map:
                        hotel['booking_url'] = url_map[hotel_name]
                    else:
                        # Try partial match
                        for name, url in url_map.items():
                            if hotel_name in name or name in hotel_name:
                                hotel['booking_url'] = url
                                break
                
                # Fix images
                fixed_images = []
                seen_hashes = set()
                for img in hotel.get('images', []):
                    fixed_img = self._fix_image_url(img)
                    if fixed_img:
                        # Simple deduplication
                        img_hash = hashlib.md5(fixed_img.encode()).hexdigest()
                        if img_hash not in seen_hashes:
                            seen_hashes.add(img_hash)
                            fixed_images.append(fixed_img)
                hotel['images'] = fixed_images
                
            self.logger.info(f"‚úÖ Fixed data for {len(hotels)} hotels")
            
        except Exception as e:
            self.logger.debug(f"Hotel data fixing error: {e}")
        
        return hotels
    
    def _parse_hotel_item(self, item: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Parse individual hotel item from weekend deals."""
        try:
            # Extract name
            name = item.get("propertyName", "Unknown Hotel")
            if name == "Unknown Hotel":
                return None
            
            # Extract ID
            property_id = item.get("propertyId", "")
            
            # Extract price
            price = None
            if "price" in item and item["price"]:
                price_data = item["price"]
                if "formattedPrice" in price_data:
                    price_str = price_data["formattedPrice"]
                    numbers = re.findall(r'[\d,]+\.?\d*', price_str.replace(',', ''))
                    if numbers:
                        price = float(numbers[0])
                elif "amount" in price_data:
                    price = float(price_data["amount"])
            
            # Extract rating
            rating = None
            review_count = None
            if "review" in item and item["review"]:
                rating = item["review"].get("score")
                review_count = item["review"].get("reviewCount")
            
            # Extract address
            address = item.get("subtitle", "")
            
            # Extract images (fix URLs immediately)
            images = []
            if "imageUrl" in item:
                image_url = self._fix_image_url(item["imageUrl"])
                if image_url:
                    images.append(image_url)
            
            return {
                "id": str(property_id),
                "name": name,
                "price_per_night": price,
                "rating": rating,
                "review_count": review_count,
                "address": address,
                "images": images,
                "amenities": [],
                "booking_url": None,  # Will be fixed later
                "source": "weekend_deals"
            }
            
        except Exception as e:
            self.logger.debug(f"Hotel item parsing error: {e}")
            return None
    
    def _fix_image_url(self, url: str) -> str:
        """Fix and enhance image URLs."""
        if not url:
            return url
            
        # Fix protocol
        if url.startswith("//"):
            url = "https:" + url
        elif url.startswith("/"):
            url = "https://cf.bstatic.com" + url
        
        # Convert to high quality
        replacements = [
            ("square60", "max1024x768"),
            ("square200", "max1024x768"),
            ("square240", "max1024x768"),
            ("square600", "max1024x768"),
            ("max300", "max1024x768"),
            ("max500", "max1024x768"),
            ("thumbnail", "max1024x768")
        ]
        
        for old, new in replacements:
            if old in url:
                url = url.replace(old, new)
                break
        
        return url
    
    def _get_nested_value(self, data: Dict[str, Any], path: List[str]) -> Any:
        """Safely get nested dictionary value."""
        current = data
        for key in path:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return None
        return current
    
    def _extract_weekend_deals_count(self, data: Dict[str, Any]) -> int:
        """Extract count of weekend deals from response."""
        deals = self._get_nested_value(data, ["data", "weekendDeals", "weekendDealsProperties"])
        return len(deals) if deals and isinstance(deals, list) else 0
    
    def _calculate_completeness(self, hotel: Dict[str, Any]) -> float:
        """Calculate data completeness score."""
        # Define required fields and their weights
        fields_weights = {
            'name': 10,
            'price_per_night': 10,
            'rating': 8,
            'address': 5,
            'booking_url': 10,
            'latitude': 8,
            'longitude': 8,
            'google_maps_url': 5,
            'images': 10,
            'amenities': 8,
            'reviews': 10,
            'description': 5,
            'surroundings': 5,
            'review_count': 3,
            'rating_breakdown': 3,
            'hotel_id': 2
        }
        
        total_weight = sum(fields_weights.values())
        achieved_weight = 0
        
        for field, weight in fields_weights.items():
            if hotel.get(field):
                if isinstance(hotel[field], list):
                    # For lists, check if not empty
                    if len(hotel[field]) > 0:
                        achieved_weight += weight
                elif isinstance(hotel[field], dict):
                    # For dicts, check if has content
                    if any(hotel[field].values()):
                        achieved_weight += weight
                elif isinstance(hotel[field], str):
                    # For strings, check if not empty
                    if hotel[field].strip():
                        achieved_weight += weight
                else:
                    # For other types, just check existence
                    achieved_weight += weight
        
        return round((achieved_weight / total_weight) * 100, 2)
    
    async def _create_browser_context(self):
        """Create optimized browser context."""
        return await self.browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            extra_http_headers={
                "Accept-Language": "en-US,en;q=0.9",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
            }
        )
    
    async def _handle_popups(self, page):
        """Handle cookie consent and other popups."""
        try:
            selectors = [
                "button[id*='accept']",
                "button:has-text('Accept')",
                "#onetrust-accept-btn-handler",
                "button:has-text('Got it')",
                ".bui-button--primary"
            ]
            
            for selector in selectors:
                try:
                    await page.click(selector, timeout=2000)
                    self.logger.debug(f"‚úÖ Handled popup: {selector}")
                    await page.wait_for_timeout(500)
                    break
                except:
                    continue
                    
        except Exception as e:
            self.logger.debug(f"Popup handling: {e}")
    
    async def _perform_search(self, page, params: Dict[str, Any]):
        """Perform search on Booking.com."""
        try:
            # Fill location
            search_input = await page.query_selector("input[name='ss']")
            if search_input:
                await search_input.fill(params["location"])
                await page.wait_for_timeout(1500)
            
            # Try to select from autocomplete
            try:
                await page.click("[data-testid='autocomplete-result']:first-child", timeout=3000)
            except:
                pass
            
            # Set dates if date inputs are visible
            try:
                checkin = await page.query_selector("[data-testid='date-display-field-start']")
                if checkin:
                    await checkin.click()
                    await page.wait_for_timeout(500)
                    # Date selection logic here if needed
            except:
                pass
            
            # Submit search
            search_button = await page.query_selector("button[type='submit']:has-text('Search')")
            if search_button:
                await search_button.click()
            else:
                # Alternative: press Enter
                await page.keyboard.press("Enter")
            
            await page.wait_for_load_state("networkidle", timeout=20000)
            
            self.logger.info("‚úÖ Search executed successfully")
            
        except Exception as e:
            self.logger.warning(f"Search execution issue: {e}")