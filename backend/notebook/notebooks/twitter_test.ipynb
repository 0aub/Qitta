{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¦ Twitter Scraper - Comprehensive Testing & Validation\n",
    "\n",
    "**Complete end-to-end testing suite for Twitter scraper with detailed analysis**\n",
    "\n",
    "This notebook provides:\n",
    "- âœ… Complete extraction testing across multiple accounts and levels\n",
    "- ğŸ“Š Detailed data validation and quality analysis\n",
    "- ğŸ” Performance metrics and success rate tracking\n",
    "- ğŸ¯ Variable counting and comprehensive result analysis\n",
    "- ğŸš€ All results in a single output for easy tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Auto-detected browser endpoint: http://browser:8004\n",
      "ğŸ¦ TWITTER SCRAPER COMPREHENSIVE TEST SUITE\n",
      "================================================================================\n",
      "ğŸ“ API Endpoint: http://browser:8004\n",
      "ğŸ“ Storage Path: /storage/scraped_data\n",
      "ğŸ¯ Test Accounts: ['naval', 'elonmusk', 'paulg', 'sama', 'vitalikbuterin']\n",
      "ğŸ”§ Test Configurations: ['basic', 'enhanced', 'comprehensive', 'date_filtered']\n",
      "âœ… API connectivity: Connected to browser service\n",
      "\n",
      "================================================================================\n",
      "ğŸ§ª TEST PHASE 1: BASIC EXTRACTION ACROSS ACCOUNTS\n",
      "================================================================================\n",
      "\n",
      "ğŸš€ SUBMITTING: Basic Extraction - @naval\n",
      "ğŸ“ Payload: {\n",
      "  \"username\": \"naval\",\n",
      "  \"scrape_posts\": true,\n",
      "  \"max_posts\": 10,\n",
      "  \"scrape_level\": 1\n",
      "}\n",
      "ğŸ†” Job ID: e9594548d6324e6092d33c6650455b15\n",
      "â³ Waiting for job e9594548d6324e6092d33c6650455b15...\n",
      "â±ï¸  running 21s (21s)\n",
      "âœ… FINISHED in 24.0s\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ANALYZING: Basic Extraction - @naval\n",
      "================================================================================\n",
      "âœ… STATUS: Task completed successfully\n",
      "ğŸ¯ TARGET: @naval\n",
      "ğŸ“Š EXTRACTION METHOD: level_1_basic\n",
      "ğŸ“ˆ SCRAPE LEVEL: 1\n",
      "ğŸ“ˆ SUCCESS RATE: 10.0%\n",
      "âœ… TOTAL EXTRACTED: 1 items\n",
      "\n",
      "ğŸ“‹ COMPREHENSIVE USER DATA ANALYSIS:\n",
      "   ğŸ‘¤ Profile: Name='Naval' | Bio=14 chars\n",
      "   ğŸ“Š Stats: 2.8M followers | 0 following\n",
      "\n",
      "ğŸ“Š EXTRACTED DATA BREAKDOWN:\n",
      "   ğŸ“ Posts: 8 items âœ…\n",
      "      ğŸ“ Sample: How to Get Rich (without getting lucky):...\n",
      "   â¤ï¸ Likes: 0 items âš ï¸ (field exists but empty)\n",
      "   @ï¸âƒ£ Mentions: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ”„ Reposts: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ–¼ï¸ Media: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ‘¥ Followers: 0 items âš ï¸ (field exists but empty)\n",
      "   â¡ï¸ Following: 0 items âš ï¸ (field exists but empty)\n",
      "\n",
      "ğŸ“ˆ TOTAL DATA ITEMS: 8 across all categories\n",
      "\n",
      "ğŸ”§ CORE FIXES VALIDATION:\n",
      "   ğŸ”„ Reposts field exists: âœ…\n",
      "   ğŸ”„ Reposts extracted: 0 âš ï¸\n",
      "   ğŸ‘¥ Followers extracted: 0 âš ï¸\n",
      "   â¡ï¸ Following extracted: 0 âš ï¸\n",
      "\n",
      "ğŸ“Š DATA QUALITY SCORE: 80%\n",
      "ğŸ‰ EXCELLENT data quality\n",
      "\n",
      "ğŸš€ SUBMITTING: Basic Extraction - @paulg\n",
      "ğŸ“ Payload: {\n",
      "  \"username\": \"paulg\",\n",
      "  \"scrape_posts\": true,\n",
      "  \"max_posts\": 10,\n",
      "  \"scrape_level\": 1\n",
      "}\n",
      "ğŸ†” Job ID: 4317c7574a54464b9718c7b4607287cd\n",
      "â³ Waiting for job 4317c7574a54464b9718c7b4607287cd...\n",
      "â±ï¸  running 24s (24s)\n",
      "âœ… FINISHED in 27.0s\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ANALYZING: Basic Extraction - @paulg\n",
      "================================================================================\n",
      "âœ… STATUS: Task completed successfully\n",
      "ğŸ¯ TARGET: @paulg\n",
      "ğŸ“Š EXTRACTION METHOD: level_1_basic\n",
      "ğŸ“ˆ SCRAPE LEVEL: 1\n",
      "ğŸ“ˆ SUCCESS RATE: 10.0%\n",
      "âœ… TOTAL EXTRACTED: 1 items\n",
      "\n",
      "ğŸ“‹ COMPREHENSIVE USER DATA ANALYSIS:\n",
      "   ğŸ‘¤ Profile: Name='Paul Graham' | Bio=500 chars\n",
      "   ğŸ“Š Stats: 2M followers | 779 following\n",
      "\n",
      "ğŸ“Š EXTRACTED DATA BREAKDOWN:\n",
      "   ğŸ“ Posts: 8 items âœ…\n",
      "      ğŸ“ Sample: Homelessness should be reframed into 3 groups....\n",
      "   â¤ï¸ Likes: 0 items âš ï¸ (field exists but empty)\n",
      "   @ï¸âƒ£ Mentions: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ”„ Reposts: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ–¼ï¸ Media: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ‘¥ Followers: 0 items âš ï¸ (field exists but empty)\n",
      "   â¡ï¸ Following: 0 items âš ï¸ (field exists but empty)\n",
      "\n",
      "ğŸ“ˆ TOTAL DATA ITEMS: 8 across all categories\n",
      "\n",
      "ğŸ”§ CORE FIXES VALIDATION:\n",
      "   ğŸ”„ Reposts field exists: âœ…\n",
      "   ğŸ”„ Reposts extracted: 0 âš ï¸\n",
      "   ğŸ‘¥ Followers extracted: 0 âš ï¸\n",
      "   â¡ï¸ Following extracted: 0 âš ï¸\n",
      "\n",
      "ğŸ“Š DATA QUALITY SCORE: 80%\n",
      "ğŸ‰ EXCELLENT data quality\n",
      "\n",
      "ğŸš€ SUBMITTING: Basic Extraction - @sama\n",
      "ğŸ“ Payload: {\n",
      "  \"username\": \"sama\",\n",
      "  \"scrape_posts\": true,\n",
      "  \"max_posts\": 10,\n",
      "  \"scrape_level\": 1\n",
      "}\n",
      "ğŸ†” Job ID: 2fc01c4b71d54c4eab6ee5e96280568d\n",
      "â³ Waiting for job 2fc01c4b71d54c4eab6ee5e96280568d...\n",
      "â±ï¸  running 27s (27s)\n",
      "âœ… FINISHED in 30.0s\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ANALYZING: Basic Extraction - @sama\n",
      "================================================================================\n",
      "âœ… STATUS: Task completed successfully\n",
      "ğŸ¯ TARGET: @sama\n",
      "ğŸ“Š EXTRACTION METHOD: level_1_basic\n",
      "ğŸ“ˆ SCRAPE LEVEL: 1\n",
      "ğŸ“ˆ SUCCESS RATE: 10.0%\n",
      "âœ… TOTAL EXTRACTED: 1 items\n",
      "\n",
      "ğŸ“‹ COMPREHENSIVE USER DATA ANALYSIS:\n",
      "   ğŸ‘¤ Profile: Name='Sam Altman' | Bio=18 chars\n",
      "   ğŸ“Š Stats: 3.9M followers | 969 following\n",
      "\n",
      "ğŸ“Š EXTRACTED DATA BREAKDOWN:\n",
      "   ğŸ“ Posts: 8 items âœ…\n",
      "      ğŸ“ Sample: You can now use gpt-5-codex to investigate and find critical...\n",
      "   â¤ï¸ Likes: 0 items âš ï¸ (field exists but empty)\n",
      "   @ï¸âƒ£ Mentions: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ”„ Reposts: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ–¼ï¸ Media: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ‘¥ Followers: 0 items âš ï¸ (field exists but empty)\n",
      "   â¡ï¸ Following: 0 items âš ï¸ (field exists but empty)\n",
      "\n",
      "ğŸ“ˆ TOTAL DATA ITEMS: 8 across all categories\n",
      "\n",
      "ğŸ”§ CORE FIXES VALIDATION:\n",
      "   ğŸ”„ Reposts field exists: âœ…\n",
      "   ğŸ”„ Reposts extracted: 0 âš ï¸\n",
      "   ğŸ‘¥ Followers extracted: 0 âš ï¸\n",
      "   â¡ï¸ Following extracted: 0 âš ï¸\n",
      "\n",
      "ğŸ“Š DATA QUALITY SCORE: 80%\n",
      "ğŸ‰ EXCELLENT data quality\n",
      "\n",
      "================================================================================\n",
      "ğŸ§ª TEST PHASE 2: SCRAPE LEVEL COMPARISON\n",
      "================================================================================\n",
      "\n",
      "ğŸš€ SUBMITTING: Level 1 Extraction - @vitalikbuterin\n",
      "ğŸ“ Payload: {\n",
      "  \"username\": \"vitalikbuterin\",\n",
      "  \"scrape_posts\": true,\n",
      "  \"max_posts\": 8,\n",
      "  \"scrape_level\": 1,\n",
      "  \"level\": 1\n",
      "}\n",
      "ğŸ†” Job ID: b41c077ea95f451c9123d856baf7477b\n",
      "â³ Waiting for job b41c077ea95f451c9123d856baf7477b...\n",
      "â±ï¸  running 30s (30s)\n",
      "âœ… FINISHED in 33.0s\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ANALYZING: Level 1 Extraction - @vitalikbuterin\n",
      "================================================================================\n",
      "âœ… STATUS: Task completed successfully\n",
      "ğŸ¯ TARGET: @vitalikbuterin\n",
      "ğŸ“Š EXTRACTION METHOD: level_1_basic\n",
      "ğŸ“ˆ SCRAPE LEVEL: 1\n",
      "ğŸ“ˆ SUCCESS RATE: 12.5%\n",
      "âœ… TOTAL EXTRACTED: 1 items\n",
      "\n",
      "ğŸ“‹ COMPREHENSIVE USER DATA ANALYSIS:\n",
      "   ğŸ‘¤ Profile: Name='vitalik.eth' | Bio=65 chars\n",
      "   ğŸ“Š Stats: 5.8M followers | 503 following\n",
      "\n",
      "ğŸ“Š EXTRACTED DATA BREAKDOWN:\n",
      "   ğŸ“ Posts: 8 items âœ…\n",
      "      ğŸ“ Sample: 0/ The Ethereum Foundation is committed to supporting the â€˜C...\n",
      "   â¤ï¸ Likes: 0 items âš ï¸ (field exists but empty)\n",
      "   @ï¸âƒ£ Mentions: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ”„ Reposts: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ–¼ï¸ Media: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ‘¥ Followers: 0 items âš ï¸ (field exists but empty)\n",
      "   â¡ï¸ Following: 0 items âš ï¸ (field exists but empty)\n",
      "\n",
      "ğŸ“ˆ TOTAL DATA ITEMS: 8 across all categories\n",
      "\n",
      "ğŸ”§ CORE FIXES VALIDATION:\n",
      "   ğŸ”„ Reposts field exists: âœ…\n",
      "   ğŸ”„ Reposts extracted: 0 âš ï¸\n",
      "   ğŸ‘¥ Followers extracted: 0 âš ï¸\n",
      "   â¡ï¸ Following extracted: 0 âš ï¸\n",
      "\n",
      "ğŸ“Š DATA QUALITY SCORE: 80%\n",
      "ğŸ‰ EXCELLENT data quality\n",
      "\n",
      "ğŸš€ SUBMITTING: Level 2 Extraction - @vitalikbuterin\n",
      "ğŸ“ Payload: {\n",
      "  \"username\": \"vitalikbuterin\",\n",
      "  \"scrape_posts\": true,\n",
      "  \"max_posts\": 8,\n",
      "  \"scrape_level\": 2,\n",
      "  \"level\": 2\n",
      "}\n",
      "ğŸ†” Job ID: 626760ab69904044b603bf7fe54eb211\n",
      "â³ Waiting for job 626760ab69904044b603bf7fe54eb211...\n",
      "â±ï¸  running 27s (27s)\n",
      "âœ… FINISHED in 30.0s\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ANALYZING: Level 2 Extraction - @vitalikbuterin\n",
      "================================================================================\n",
      "âœ… STATUS: Task completed successfully\n",
      "ğŸ¯ TARGET: @vitalikbuterin\n",
      "ğŸ“Š EXTRACTION METHOD: level_2_full_profile\n",
      "ğŸ“ˆ SCRAPE LEVEL: 2\n",
      "ğŸ“ˆ SUCCESS RATE: 12.5%\n",
      "âœ… TOTAL EXTRACTED: 1 items\n",
      "\n",
      "ğŸ“‹ COMPREHENSIVE USER DATA ANALYSIS:\n",
      "   ğŸ‘¤ Profile: Name='vitalik.eth' | Bio=65 chars\n",
      "   ğŸ“Š Stats: 5.8M followers | 503 following\n",
      "\n",
      "ğŸ“Š EXTRACTED DATA BREAKDOWN:\n",
      "   ğŸ“ Posts: 8 items âœ…\n",
      "      ğŸ“ Sample: 0/ The Ethereum Foundation is committed to supporting the â€˜C...\n",
      "   â¤ï¸ Likes: 0 items âš ï¸ (field exists but empty)\n",
      "   @ï¸âƒ£ Mentions: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ”„ Reposts: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ–¼ï¸ Media: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ‘¥ Followers: 0 items âš ï¸ (field exists but empty)\n",
      "   â¡ï¸ Following: 0 items âš ï¸ (field exists but empty)\n",
      "\n",
      "ğŸ“ˆ TOTAL DATA ITEMS: 8 across all categories\n",
      "\n",
      "ğŸ”§ CORE FIXES VALIDATION:\n",
      "   ğŸ”„ Reposts field exists: âœ…\n",
      "   ğŸ”„ Reposts extracted: 0 âš ï¸\n",
      "   ğŸ‘¥ Followers extracted: 0 âš ï¸\n",
      "   â¡ï¸ Following extracted: 0 âš ï¸\n",
      "\n",
      "ğŸ“Š DATA QUALITY SCORE: 80%\n",
      "ğŸ‰ EXCELLENT data quality\n",
      "\n",
      "ğŸš€ SUBMITTING: Level 3 Extraction - @vitalikbuterin\n",
      "ğŸ“ Payload: {\n",
      "  \"username\": \"vitalikbuterin\",\n",
      "  \"scrape_posts\": true,\n",
      "  \"max_posts\": 8,\n",
      "  \"scrape_level\": 3,\n",
      "  \"level\": 3\n",
      "}\n",
      "ğŸ†” Job ID: 04da1cfad2d343d7b34ab012fb9ef5e6\n",
      "â³ Waiting for job 04da1cfad2d343d7b34ab012fb9ef5e6...\n",
      "â±ï¸  running 36s (36s)\n",
      "âœ… FINISHED in 39.0s\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ANALYZING: Level 3 Extraction - @vitalikbuterin\n",
      "================================================================================\n",
      "âœ… STATUS: Task completed successfully\n",
      "ğŸ¯ TARGET: @vitalikbuterin\n",
      "ğŸ“Š EXTRACTION METHOD: level_3_with_media\n",
      "ğŸ“ˆ SCRAPE LEVEL: 3\n",
      "ğŸ“ˆ SUCCESS RATE: 12.5%\n",
      "âœ… TOTAL EXTRACTED: 1 items\n",
      "\n",
      "ğŸ“‹ COMPREHENSIVE USER DATA ANALYSIS:\n",
      "   ğŸ‘¤ Profile: Name='vitalik.eth' | Bio=65 chars\n",
      "   ğŸ“Š Stats: 5.8M followers | 503 following\n",
      "\n",
      "ğŸ“Š EXTRACTED DATA BREAKDOWN:\n",
      "   ğŸ“ Posts: 8 items âœ…\n",
      "      ğŸ“ Sample: 0/ The Ethereum Foundation is committed to supporting the â€˜C...\n",
      "   â¤ï¸ Likes: 0 items âš ï¸ (field exists but empty)\n",
      "   @ï¸âƒ£ Mentions: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ”„ Reposts: 0 items âš ï¸ (field exists but empty)\n",
      "   ğŸ–¼ï¸ Media: 25 items âœ…\n",
      "      ğŸ“ Sample: I choose balance. First-level balance....\n",
      "   ğŸ‘¥ Followers: 0 items âš ï¸ (field exists but empty)\n",
      "   â¡ï¸ Following: 0 items âš ï¸ (field exists but empty)\n",
      "\n",
      "ğŸ“ˆ TOTAL DATA ITEMS: 33 across all categories\n",
      "\n",
      "ğŸ”§ CORE FIXES VALIDATION:\n",
      "   ğŸ”„ Reposts field exists: âœ…\n",
      "   ğŸ”„ Reposts extracted: 0 âš ï¸\n",
      "   ğŸ‘¥ Followers extracted: 0 âš ï¸\n",
      "   â¡ï¸ Following extracted: 0 âš ï¸\n",
      "\n",
      "ğŸ“Š DATA QUALITY SCORE: 85%\n",
      "ğŸ‰ EXCELLENT data quality\n",
      "\n",
      "ğŸš€ SUBMITTING: Level 4 Extraction - @vitalikbuterin\n",
      "ğŸ“ Payload: {\n",
      "  \"username\": \"vitalikbuterin\",\n",
      "  \"scrape_posts\": true,\n",
      "  \"max_posts\": 8,\n",
      "  \"scrape_level\": 4,\n",
      "  \"level\": 4\n",
      "}\n",
      "ğŸ†” Job ID: 2cbf3b850c514696a7460f41ba963d39\n",
      "â³ Waiting for job 2cbf3b850c514696a7460f41ba963d39...\n",
      "â±ï¸  running 6m 0s (360s))\n",
      "âœ… FINISHED in 363.4s\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ANALYZING: Level 4 Extraction - @vitalikbuterin\n",
      "================================================================================\n",
      "âœ… STATUS: Task completed successfully\n",
      "ğŸ¯ TARGET: @vitalikbuterin\n",
      "ğŸ“Š EXTRACTION METHOD: level_4_comprehensive\n",
      "ğŸ“ˆ SCRAPE LEVEL: 4\n",
      "ğŸ“ˆ SUCCESS RATE: 12.5%\n",
      "âœ… TOTAL EXTRACTED: 1 items\n",
      "\n",
      "ğŸ“‹ COMPREHENSIVE USER DATA ANALYSIS:\n",
      "   ğŸ‘¤ Profile: Name='vitalik.eth' | Bio=65 chars\n",
      "   ğŸ“Š Stats: 5.8M followers | 503 following\n",
      "\n",
      "ğŸ“Š EXTRACTED DATA BREAKDOWN:\n",
      "   ğŸ“ Posts: 50 items âœ…\n",
      "      ğŸ“ Sample: 0/ The Ethereum Foundation is committed to supporting the â€˜C...\n",
      "   â¤ï¸ Likes: 1 items âœ…\n",
      "      ğŸ“ Sample: {'type': 'access_restricted', 'message': 'Likes for @vitalik...\n",
      "   @ï¸âƒ£ Mentions: 24 items âœ…\n",
      "      ğŸ“ Sample: gotta love the little trembling at the end...\n",
      "   ğŸ”„ Reposts: 1 items âœ…\n",
      "      ğŸ“ Sample: {'type': 'access_restricted', 'message': 'Profile @vitalikbu...\n",
      "   ğŸ–¼ï¸ Media: 25 items âœ…\n",
      "      ğŸ“ Sample: I choose balance. First-level balance....\n",
      "   ğŸ‘¥ Followers: 86 items âœ…\n",
      "      ğŸ“ Sample: {'username': '@vitalikbuterin', 'display_name': 'vitalik.eth...\n",
      "   â¡ï¸ Following: 99 items âœ…\n",
      "      ğŸ“ Sample: {'username': '@vitalikbuterin', 'display_name': 'vitalik.eth...\n",
      "\n",
      "ğŸ“ˆ TOTAL DATA ITEMS: 286 across all categories\n",
      "\n",
      "ğŸ”§ CORE FIXES VALIDATION:\n",
      "   ğŸ”„ Reposts field exists: âœ…\n",
      "   ğŸ”„ Reposts extracted: 1 âœ…\n",
      "   ğŸ‘¥ Followers extracted: 86 âœ…\n",
      "   â¡ï¸ Following extracted: 99 âœ…\n",
      "\n",
      "ğŸ“Š DATA QUALITY SCORE: 90%\n",
      "ğŸ‰ EXCELLENT data quality\n",
      "\n",
      "================================================================================\n",
      "ğŸ§ª TEST PHASE 3: COMPREHENSIVE EXTRACTION\n",
      "================================================================================\n",
      "\n",
      "ğŸš€ SUBMITTING: Comprehensive Extraction - @naval\n",
      "ğŸ“ Payload: {\n",
      "  \"username\": \"naval\",\n",
      "  \"scrape_posts\": true,\n",
      "  \"max_posts\": 20,\n",
      "  \"scrape_likes\": true,\n",
      "  \"max_likes\": 10,\n",
      "  \"scrape_mentions\": true,\n",
      "  \"max_mentions\": 5,\n",
      "  \"scrape_media\": true,\n",
      "  \"max_media\": 5,\n",
      "  \"scrape_level\": 4\n",
      "}\n",
      "ğŸ†” Job ID: 8fb0c4b4aa154a10b5016992e76f35bd\n",
      "â³ Waiting for job 8fb0c4b4aa154a10b5016992e76f35bd...\n",
      "â±ï¸  running 7m 6s (426s))\n",
      "âœ… FINISHED in 429.4s\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ANALYZING: Comprehensive Extraction - @naval\n",
      "================================================================================\n",
      "âœ… STATUS: Task completed successfully\n",
      "ğŸ¯ TARGET: @naval\n",
      "ğŸ“Š EXTRACTION METHOD: level_4_comprehensive\n",
      "ğŸ“ˆ SCRAPE LEVEL: 4\n",
      "ğŸ“ˆ SUCCESS RATE: 5.0%\n",
      "âœ… TOTAL EXTRACTED: 1 items\n",
      "\n",
      "ğŸ“‹ COMPREHENSIVE USER DATA ANALYSIS:\n",
      "   ğŸ‘¤ Profile: Name='Naval' | Bio=14 chars\n",
      "   ğŸ“Š Stats: 2.8M followers | 0 following\n",
      "\n",
      "ğŸ“Š EXTRACTED DATA BREAKDOWN:\n",
      "   ğŸ“ Posts: 50 items âœ…\n",
      "      ğŸ“ Sample: How to Get Rich (without getting lucky):...\n",
      "   â¤ï¸ Likes: 1 items âœ…\n",
      "      ğŸ“ Sample: {'type': 'access_restricted', 'message': 'Likes for @naval a...\n",
      "   @ï¸âƒ£ Mentions: 14 items âœ…\n",
      "      ğŸ“ Sample: Emily Lazar...\n",
      "   ğŸ”„ Reposts: 1 items âœ…\n",
      "      ğŸ“ Sample: {'type': 'access_restricted', 'message': 'Profile @naval is ...\n",
      "   ğŸ–¼ï¸ Media: 15 items âœ…\n",
      "      ğŸ“ Sample: {'type': 'image', 'url': 'https://pbs.twimg.com/media/G0CCur...\n",
      "   ğŸ‘¥ Followers: 95 items âœ…\n",
      "      ğŸ“ Sample: {'username': '@naval', 'display_name': 'Naval', 'bio': '', '...\n",
      "   â¡ï¸ Following: 1 items âœ…\n",
      "      ğŸ“ Sample: {'username': '@naval', 'display_name': 'Naval', 'bio': '', '...\n",
      "\n",
      "ğŸ“ˆ TOTAL DATA ITEMS: 177 across all categories\n",
      "\n",
      "ğŸ”§ CORE FIXES VALIDATION:\n",
      "   ğŸ”„ Reposts field exists: âœ…\n",
      "   ğŸ”„ Reposts extracted: 1 âœ…\n",
      "   ğŸ‘¥ Followers extracted: 95 âœ…\n",
      "   â¡ï¸ Following extracted: 1 âœ…\n",
      "\n",
      "ğŸ“Š DATA QUALITY SCORE: 90%\n",
      "ğŸ‰ EXCELLENT data quality\n",
      "\n",
      "================================================================================\n",
      "ğŸ§ª TEST PHASE 4: DATE FILTERING PERFORMANCE\n",
      "================================================================================\n",
      "\n",
      "ğŸš€ SUBMITTING: Date Filter (last_day) - @sama\n",
      "ğŸ“ Payload: {\n",
      "  \"username\": \"sama\",\n",
      "  \"scrape_posts\": true,\n",
      "  \"max_posts\": 15,\n",
      "  \"enable_date_filtering\": true,\n",
      "  \"date_range\": \"last_day\",\n",
      "  \"scrape_level\": 4\n",
      "}\n",
      "ğŸ†” Job ID: 4c3d2b74dc9e4265bf6640b24f5ca56c\n",
      "â³ Waiting for job 4c3d2b74dc9e4265bf6640b24f5ca56c...\n",
      "â±ï¸  running 6m 57s (417s)\n",
      "âœ… FINISHED in 420.4s\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ANALYZING: Date Filter (last_day) - @sama\n",
      "================================================================================\n",
      "âœ… STATUS: Task completed successfully\n",
      "ğŸ¯ TARGET: @sama\n",
      "ğŸ“Š EXTRACTION METHOD: level_4_comprehensive\n",
      "ğŸ“ˆ SCRAPE LEVEL: 4\n",
      "ğŸ“ˆ SUCCESS RATE: 6.7%\n",
      "âœ… TOTAL EXTRACTED: 1 items\n",
      "\n",
      "ğŸ“‹ COMPREHENSIVE USER DATA ANALYSIS:\n",
      "   ğŸ‘¤ Profile: Name='Sam Altman' | Bio=18 chars\n",
      "   ğŸ“Š Stats: 3.9M followers | 969 following\n",
      "\n",
      "ğŸ“Š EXTRACTED DATA BREAKDOWN:\n",
      "   ğŸ“ Posts: 50 items âœ…\n",
      "      ğŸ“ Sample: You can now use gpt-5-codex to investigate and find critical...\n",
      "   â¤ï¸ Likes: 1 items âœ…\n",
      "      ğŸ“ Sample: {'type': 'access_restricted', 'message': 'Likes for @sama ar...\n",
      "   @ï¸âƒ£ Mentions: 8 items âœ…\n",
      "      ğŸ“ Sample: Maybe you need to tell what it will become...\n",
      "   ğŸ”„ Reposts: 1 items âœ…\n",
      "      ğŸ“ Sample: {'type': 'access_restricted', 'message': 'Profile @sama is n...\n",
      "   ğŸ–¼ï¸ Media: 25 items âœ…\n",
      "      ğŸ“ Sample: {'type': 'image', 'url': 'https://pbs.twimg.com/media/G079wT...\n",
      "   ğŸ‘¥ Followers: 110 items âœ…\n",
      "      ğŸ“ Sample: {'username': '@sama', 'display_name': 'Sam Altman', 'bio': '...\n",
      "   â¡ï¸ Following: 132 items âœ…\n",
      "      ğŸ“ Sample: {'username': '@sama', 'display_name': 'Sam Altman', 'bio': '...\n",
      "\n",
      "ğŸ“ˆ TOTAL DATA ITEMS: 327 across all categories\n",
      "\n",
      "ğŸ”§ CORE FIXES VALIDATION:\n",
      "   ğŸ”„ Reposts field exists: âœ…\n",
      "   ğŸ”„ Reposts extracted: 1 âœ…\n",
      "   ğŸ‘¥ Followers extracted: 110 âœ…\n",
      "   â¡ï¸ Following extracted: 132 âœ…\n",
      "\n",
      "ğŸ“Š DATA QUALITY SCORE: 90%\n",
      "ğŸ‰ EXCELLENT data quality\n",
      "\n",
      "ğŸš€ SUBMITTING: Date Filter (last_week) - @sama\n",
      "ğŸ“ Payload: {\n",
      "  \"username\": \"sama\",\n",
      "  \"scrape_posts\": true,\n",
      "  \"max_posts\": 15,\n",
      "  \"enable_date_filtering\": true,\n",
      "  \"date_range\": \"last_week\",\n",
      "  \"scrape_level\": 4\n",
      "}\n",
      "ğŸ†” Job ID: ff0007568cb34108bae104275b88699b\n",
      "â³ Waiting for job ff0007568cb34108bae104275b88699b...\n",
      "â±ï¸  running 6m 54s (414s)\n",
      "âœ… FINISHED in 417.4s\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ANALYZING: Date Filter (last_week) - @sama\n",
      "================================================================================\n",
      "âœ… STATUS: Task completed successfully\n",
      "ğŸ¯ TARGET: @sama\n",
      "ğŸ“Š EXTRACTION METHOD: level_4_comprehensive\n",
      "ğŸ“ˆ SCRAPE LEVEL: 4\n",
      "ğŸ“ˆ SUCCESS RATE: 6.7%\n",
      "âœ… TOTAL EXTRACTED: 1 items\n",
      "\n",
      "ğŸ“‹ COMPREHENSIVE USER DATA ANALYSIS:\n",
      "   ğŸ‘¤ Profile: Name='Sam Altman' | Bio=18 chars\n",
      "   ğŸ“Š Stats: 3.9M followers | 969 following\n",
      "\n",
      "ğŸ“Š EXTRACTED DATA BREAKDOWN:\n",
      "   ğŸ“ Posts: 50 items âœ…\n",
      "      ğŸ“ Sample: You can now use gpt-5-codex to investigate and find critical...\n",
      "   â¤ï¸ Likes: 1 items âœ…\n",
      "      ğŸ“ Sample: {'type': 'access_restricted', 'message': 'Likes for @sama ar...\n",
      "   @ï¸âƒ£ Mentions: 16 items âœ…\n",
      "      ğŸ“ Sample: #4oforever #keep4o #o3forever #keepo3 #o4miniforever #keepo4...\n",
      "   ğŸ”„ Reposts: 1 items âœ…\n",
      "      ğŸ“ Sample: {'type': 'access_restricted', 'message': 'Profile @sama is n...\n",
      "   ğŸ–¼ï¸ Media: 25 items âœ…\n",
      "      ğŸ“ Sample: {'type': 'image', 'url': 'https://pbs.twimg.com/media/G079wT...\n",
      "   ğŸ‘¥ Followers: 110 items âœ…\n",
      "      ğŸ“ Sample: {'username': '@sama', 'display_name': 'Sam Altman', 'bio': '...\n",
      "   â¡ï¸ Following: 132 items âœ…\n",
      "      ğŸ“ Sample: {'username': '@sama', 'display_name': 'Sam Altman', 'bio': '...\n",
      "\n",
      "ğŸ“ˆ TOTAL DATA ITEMS: 335 across all categories\n",
      "\n",
      "ğŸ”§ CORE FIXES VALIDATION:\n",
      "   ğŸ”„ Reposts field exists: âœ…\n",
      "   ğŸ”„ Reposts extracted: 1 âœ…\n",
      "   ğŸ‘¥ Followers extracted: 110 âœ…\n",
      "   â¡ï¸ Following extracted: 132 âœ…\n",
      "\n",
      "ğŸ“Š DATA QUALITY SCORE: 90%\n",
      "ğŸ‰ EXCELLENT data quality\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š COMPREHENSIVE TEST RESULTS & ANALYSIS\n",
      "================================================================================\n",
      "ğŸ“ˆ OVERALL STATISTICS:\n",
      "   ğŸ¯ Total Tests: 10\n",
      "   âœ… Successful: 10 (100.0%)\n",
      "   âŒ Failed: 0\n",
      "   ğŸ“Š Tests with Data: 10\n",
      "   ğŸ† Average Quality Score: 84.5%\n",
      "\n",
      "ğŸ“‹ DETAILED TEST RESULTS:\n",
      "   âœ… Basic Extraction - @naval: (8 items) Q:80%\n",
      "   âœ… Basic Extraction - @paulg: (8 items) Q:80%\n",
      "   âœ… Basic Extraction - @sama: (8 items) Q:80%\n",
      "   âœ… Level 1 Extraction - @vitalikbuterin: (8 items) Q:80%\n",
      "   âœ… Level 2 Extraction - @vitalikbuterin: (8 items) Q:80%\n",
      "   âœ… Level 3 Extraction - @vitalikbuterin: (33 items) Q:85%\n",
      "   âœ… Level 4 Extraction - @vitalikbuterin: (286 items) Q:90%\n",
      "   âœ… Comprehensive Extraction - @naval: (177 items) Q:90%\n",
      "   âœ… Date Filter (last_day) - @sama: (327 items) Q:90%\n",
      "   âœ… Date Filter (last_week) - @sama: (335 items) Q:90%\n",
      "\n",
      "ğŸ“Š DATA EXTRACTION ANALYSIS:\n",
      "   ğŸ“ˆ Tests with Data: 10/10 (100.0%)\n",
      "   ğŸ“Š Total Items Extracted: 1198\n",
      "   ğŸ“ˆ Average Items per Successful Test: 119.8\n",
      "\n",
      "ğŸ“Š DATA TYPES EXTRACTED:\n",
      "   ğŸ‘¥ Followers: 401 total items\n",
      "   â¡ï¸ Following: 364 total items\n",
      "   â¤ï¸ Likes: 4 total items\n",
      "   ğŸ–¼ï¸ Media: 115 total items\n",
      "   @ï¸âƒ£ Mentions: 62 total items\n",
      "   ğŸ“ Posts: 248 total items\n",
      "   ğŸ“Š Profile: 10 total items\n",
      "   ğŸ”„ Reposts: 4 total items\n",
      "\n",
      "ğŸ”§ CORE FIXES SUMMARY:\n",
      "   ğŸ”„ Reposts field: âœ… FIXED\n",
      "   ğŸ“Š Tests with reposts data: 10/10\n",
      "\n",
      "ğŸ¯ OVERALL ASSESSMENT:\n",
      "ğŸ‰ EXCELLENT - Twitter scraper is working perfectly!\n",
      "\n",
      "ğŸ“ RECENT JOB DATA:\n",
      "   ğŸ“‚ ff06aff1406f4e81b7aad85048f0ed02: 2 files\n",
      "   ğŸ“‚ ff0007568cb34108bae104275b88699b: 2 files\n",
      "   ğŸ“‚ fe5693ec88a040c8bfb64686b6f0d5f6: 2 files\n",
      "   ğŸ“‚ fb2e756a970448f8b32291cfb3a9c65c: 1 files\n",
      "   ğŸ“‚ f6ed52b947b147e794780cee6dbcc212: 2 files\n",
      "\n",
      "ğŸ”— Raw data files: /storage/scraped_data/twitter/\n",
      "ğŸ‰ COMPREHENSIVE TESTING COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "ğŸ¦ COMPREHENSIVE TWITTER SCRAPER TEST SUITE\n",
    "==========================================\n",
    "\n",
    "Complete testing and validation suite for Twitter scraper functionality.\n",
    "Provides detailed analysis, validation, and performance metrics in a single output.\n",
    "\"\"\"\n",
    "\n",
    "import os, time, pathlib, pprint, requests, json\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "# Configuration - Auto-detect correct endpoint\n",
    "def find_browser_endpoint():\n",
    "    \"\"\"Auto-detect the correct browser endpoint.\"\"\"\n",
    "    import urllib.request\n",
    "    \n",
    "    # Try different possible endpoints\n",
    "    endpoints = [\n",
    "        \"http://browser:8001\",\n",
    "        \"http://browser:8004\", \n",
    "        \"http://localhost:8001\",\n",
    "        \"http://localhost:8004\"\n",
    "    ]\n",
    "    \n",
    "    for endpoint in endpoints:\n",
    "        try:\n",
    "            with urllib.request.urlopen(f\"{endpoint}/healthz\", timeout=2) as response:\n",
    "                if response.status == 200:\n",
    "                    print(f\"ğŸ” Auto-detected browser endpoint: {endpoint}\")\n",
    "                    return endpoint\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Default fallback\n",
    "    return \"http://localhost:8001\"\n",
    "\n",
    "EP = find_browser_endpoint()  # Auto-detect correct endpoint\n",
    "SCRAPED = pathlib.Path(\"/storage/scraped_data\")\n",
    "\n",
    "# Test accounts with different characteristics\n",
    "TEST_ACCOUNTS = {\n",
    "    \"naval\": \"High-quality tweets, philosophy\",\n",
    "    \"elonmusk\": \"High activity, mixed content\",\n",
    "    \"paulg\": \"Startup advice, essays\",\n",
    "    \"sama\": \"AI/tech commentary\",\n",
    "    \"vitalikbuterin\": \"Crypto/blockchain content\"\n",
    "}\n",
    "\n",
    "# Test configurations\n",
    "TEST_CONFIGS = {\n",
    "    \"basic\": {\n",
    "        \"scrape_posts\": True,\n",
    "        \"max_posts\": 10,\n",
    "        \"scrape_level\": 1\n",
    "    },\n",
    "    \"enhanced\": {\n",
    "        \"scrape_posts\": True,\n",
    "        \"max_posts\": 15,\n",
    "        \"scrape_likes\": True,\n",
    "        \"max_likes\": 5,\n",
    "        \"scrape_level\": 2\n",
    "    },\n",
    "    \"comprehensive\": {\n",
    "        \"scrape_posts\": True,\n",
    "        \"max_posts\": 20,\n",
    "        \"scrape_likes\": True,\n",
    "        \"max_likes\": 10,\n",
    "        \"scrape_mentions\": True,\n",
    "        \"max_mentions\": 5,\n",
    "        \"scrape_media\": True,\n",
    "        \"max_media\": 5,\n",
    "        \"scrape_level\": 4\n",
    "    },\n",
    "    \"date_filtered\": {\n",
    "        \"scrape_posts\": True,\n",
    "        \"max_posts\": 25,\n",
    "        \"enable_date_filtering\": True,\n",
    "        \"date_range\": \"last_week\",\n",
    "        \"scrape_level\": 4\n",
    "    }\n",
    "}\n",
    "\n",
    "class TwitterTestSuite:\n",
    "    \"\"\"Comprehensive Twitter scraper test suite.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "        self.performance_metrics = {}\n",
    "        self.validation_results = {}\n",
    "        self.total_tests = 0\n",
    "        self.successful_tests = 0\n",
    "        self.failed_tests = 0\n",
    "        self.data_quality_scores = []\n",
    "        \n",
    "    def wait_for_job(self, job_id: str, every: int = 3) -> Dict[str, Any]:\n",
    "        \"\"\"Wait for job completion and return result.\"\"\"\n",
    "        print(f\"â³ Waiting for job {job_id}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                rec = requests.get(f\"{EP}/jobs/{job_id}\", timeout=10).json()\n",
    "                status = rec[\"status\"]\n",
    "                \n",
    "                if status not in {\"finished\", \"error\"}:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    print(f\"\\râ±ï¸  {rec.get('status_with_elapsed', status)} ({elapsed:.0f}s)\", end=\"\")\n",
    "                else:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    print(f\"\\nâœ… {status.upper()} in {elapsed:.1f}s\")\n",
    "                    return rec\n",
    "                    \n",
    "                time.sleep(every)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâŒ Error checking job status: {e}\")\n",
    "                return {\"status\": \"error\", \"error\": str(e)}\n",
    "\n",
    "    def submit_job(self, task: str, payload: Dict[str, Any], test_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Submit job and wait for completion.\"\"\"\n",
    "        print(f\"\\nğŸš€ SUBMITTING: {test_name}\")\n",
    "        print(f\"ğŸ“ Payload: {json.dumps(payload, indent=2)}\")\n",
    "        \n",
    "        try:\n",
    "            r = requests.post(f\"{EP}/jobs/{task}\", json=payload, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            jid = r.json()[\"job_id\"]\n",
    "            print(f\"ğŸ†” Job ID: {jid}\")\n",
    "            \n",
    "            result = self.wait_for_job(jid)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Job submission failed: {e}\")\n",
    "            return {\"status\": \"error\", \"error\": str(e)}\n",
    "\n",
    "    def analyze_extraction_result(self, result: Dict[str, Any], test_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Comprehensive analysis of extraction results.\"\"\"\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"ğŸ” ANALYZING: {test_name}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        analysis = {\n",
    "            \"test_name\": test_name,\n",
    "            \"status\": result.get(\"status\", \"unknown\"),\n",
    "            \"job_id\": result.get(\"job_id\", \"N/A\"),\n",
    "            \"execution_time\": 0,\n",
    "            \"data_extracted\": False,\n",
    "            \"total_items\": 0,\n",
    "            \"data_types\": {},\n",
    "            \"quality_score\": 0,\n",
    "            \"issues\": [],\n",
    "            \"success\": False\n",
    "        }\n",
    "        \n",
    "        if result[\"status\"] == \"error\":\n",
    "            error_msg = result.get('error', 'Unknown error')\n",
    "            print(f\"âŒ FAILED: {error_msg}\")\n",
    "            analysis[\"issues\"].append(f\"Job failed: {error_msg}\")\n",
    "            return analysis\n",
    "        \n",
    "        if \"result\" not in result:\n",
    "            print(f\"âŒ No result data found\")\n",
    "            analysis[\"issues\"].append(\"No result data in response\")\n",
    "            return analysis\n",
    "        \n",
    "        res = result[\"result\"]\n",
    "        metadata = res.get(\"search_metadata\", {})\n",
    "        data = res.get(\"data\", [])\n",
    "        \n",
    "        # Basic extraction info\n",
    "        print(f\"âœ… STATUS: Task completed successfully\")\n",
    "        print(f\"ğŸ¯ TARGET: @{metadata.get('target_username', 'N/A')}\")\n",
    "        print(f\"ğŸ“Š EXTRACTION METHOD: {metadata.get('extraction_method', 'N/A')}\")\n",
    "        print(f\"ğŸ“ˆ SCRAPE LEVEL: {metadata.get('scrape_level', 'N/A')}\")\n",
    "        print(f\"ğŸ“ˆ SUCCESS RATE: {metadata.get('success_rate', 0):.1%}\")\n",
    "        \n",
    "        # Update analysis\n",
    "        analysis[\"success\"] = True\n",
    "        analysis[\"total_items\"] = len(data)\n",
    "        analysis[\"data_extracted\"] = len(data) > 0\n",
    "        \n",
    "        if not data:\n",
    "            print(f\"âš ï¸ NO DATA EXTRACTED - 0 items returned\")\n",
    "            analysis[\"issues\"].append(\"No data extracted\")\n",
    "            return analysis\n",
    "        \n",
    "        print(f\"âœ… TOTAL EXTRACTED: {len(data)} items\")\n",
    "        \n",
    "        # Analyze data structure\n",
    "        first_item = data[0] if data else {}\n",
    "        \n",
    "        # Check if comprehensive user data (profile + posts structure)\n",
    "        if isinstance(first_item, dict) and 'profile' in first_item:\n",
    "            self._analyze_comprehensive_data(first_item, analysis)\n",
    "        else:\n",
    "            self._analyze_direct_posts(data, analysis)\n",
    "        \n",
    "        # Calculate quality score\n",
    "        quality_score = self._calculate_quality_score(data, analysis)\n",
    "        analysis[\"quality_score\"] = quality_score\n",
    "        \n",
    "        print(f\"\\nğŸ“Š DATA QUALITY SCORE: {quality_score:.0f}%\")\n",
    "        if quality_score >= 80:\n",
    "            print(f\"ğŸ‰ EXCELLENT data quality\")\n",
    "        elif quality_score >= 60:\n",
    "            print(f\"âœ… GOOD data quality\")\n",
    "        elif quality_score >= 40:\n",
    "            print(f\"âš ï¸ FAIR data quality\")\n",
    "        else:\n",
    "            print(f\"âŒ POOR data quality\")\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _analyze_comprehensive_data(self, data: Dict[str, Any], analysis: Dict[str, Any]):\n",
    "        \"\"\"Analyze comprehensive user data structure.\"\"\"\n",
    "        print(f\"\\nğŸ“‹ COMPREHENSIVE USER DATA ANALYSIS:\")\n",
    "        \n",
    "        # Profile analysis\n",
    "        profile = data.get('profile', {})\n",
    "        if profile:\n",
    "            print(f\"   ğŸ‘¤ Profile: Name='{profile.get('display_name', 'N/A')}' | Bio={len(profile.get('bio', ''))} chars\")\n",
    "            print(f\"   ğŸ“Š Stats: {profile.get('followers_count', 'N/A')} followers | {profile.get('following_count', 'N/A')} following\")\n",
    "            analysis[\"data_types\"][\"profile\"] = 1\n",
    "        \n",
    "        # Data types analysis - INCLUDING REPOSTS CHECK\n",
    "        data_types = ['posts', 'likes', 'mentions', 'reposts', 'media', 'followers', 'following']\n",
    "        total_items = 0\n",
    "        \n",
    "        print(f\"\\nğŸ“Š EXTRACTED DATA BREAKDOWN:\")\n",
    "        for data_type in data_types:\n",
    "            items = data.get(data_type, [])\n",
    "            if items and isinstance(items, list):\n",
    "                count = len(items)\n",
    "                total_items += count\n",
    "                analysis[\"data_types\"][data_type] = count\n",
    "                \n",
    "                emoji = self._get_emoji(data_type)\n",
    "                status = \"âœ…\" if count > 0 else \"âŒ\"\n",
    "                print(f\"   {emoji} {data_type.title()}: {count} items {status}\")\n",
    "                \n",
    "                # Show sample if available\n",
    "                if count > 0 and isinstance(items[0], dict):\n",
    "                    sample = items[0]\n",
    "                    sample_text = sample.get('text', sample.get('content', str(sample)))[:60]\n",
    "                    print(f\"      ğŸ“ Sample: {sample_text}{'...' if len(str(sample)) > 60 else ''}\")\n",
    "            else:\n",
    "                # Check if field exists but is empty\n",
    "                if data_type in data:\n",
    "                    emoji = self._get_emoji(data_type)\n",
    "                    print(f\"   {emoji} {data_type.title()}: 0 items âš ï¸ (field exists but empty)\")\n",
    "                    analysis[\"data_types\"][data_type] = 0\n",
    "                else:\n",
    "                    emoji = self._get_emoji(data_type)\n",
    "                    print(f\"   {emoji} {data_type.title()}: MISSING FIELD âŒ\")\n",
    "                    if data_type == 'reposts':\n",
    "                        analysis[\"issues\"].append(\"CRITICAL: reposts field missing from output structure\")\n",
    "        \n",
    "        analysis[\"total_items\"] = total_items\n",
    "        print(f\"\\nğŸ“ˆ TOTAL DATA ITEMS: {total_items} across all categories\")\n",
    "        \n",
    "        # NEW: CORE FIXES VALIDATION\n",
    "        print(f\"\\nğŸ”§ CORE FIXES VALIDATION:\")\n",
    "        reposts_field_exists = 'reposts' in data\n",
    "        reposts_count = len(data.get('reposts', []))\n",
    "        followers_count = len(data.get('followers', []))\n",
    "        following_count = len(data.get('following', []))\n",
    "        \n",
    "        print(f\"   ğŸ”„ Reposts field exists: {'âœ…' if reposts_field_exists else 'âŒ BROKEN'}\")\n",
    "        print(f\"   ğŸ”„ Reposts extracted: {reposts_count} {'âœ…' if reposts_count > 0 else 'âš ï¸'}\")\n",
    "        print(f\"   ğŸ‘¥ Followers extracted: {followers_count} {'âœ…' if followers_count > 0 else 'âš ï¸'}\")\n",
    "        print(f\"   â¡ï¸ Following extracted: {following_count} {'âœ…' if following_count > 0 else 'âš ï¸'}\")\n",
    "        \n",
    "        if not reposts_field_exists:\n",
    "            analysis[\"issues\"].append(\"CRITICAL: reposts field missing - core fix failed\")\n",
    "    \n",
    "    def _analyze_direct_posts(self, data: List[Dict], analysis: Dict[str, Any]):\n",
    "        \"\"\"Analyze direct posts/tweets data.\"\"\"\n",
    "        print(f\"\\nğŸ“ DIRECT POSTS ANALYSIS:\")\n",
    "        print(f\"   ğŸ“Š Total Posts: {len(data)}\")\n",
    "        \n",
    "        analysis[\"data_types\"][\"posts\"] = len(data)\n",
    "        \n",
    "        # Count different data attributes\n",
    "        posts_with_text = sum(1 for p in data if isinstance(p, dict) and p.get('text'))\n",
    "        posts_with_dates = sum(1 for p in data if isinstance(p, dict) and p.get('date'))\n",
    "        posts_with_metrics = sum(1 for p in data if isinstance(p, dict) and any(k in p for k in ['likes', 'retweets', 'replies']))\n",
    "        \n",
    "        print(f\"   ğŸ“ With text: {posts_with_text}/{len(data)} ({posts_with_text/len(data)*100:.0f}%)\")\n",
    "        print(f\"   ğŸ“… With dates: {posts_with_dates}/{len(data)} ({posts_with_dates/len(data)*100:.0f}%)\")\n",
    "        print(f\"   ğŸ“Š With metrics: {posts_with_metrics}/{len(data)} ({posts_with_metrics/len(data)*100:.0f}%)\")\n",
    "        \n",
    "        # Show samples\n",
    "        sample_count = min(3, len(data))\n",
    "        for i in range(sample_count):\n",
    "            post = data[i]\n",
    "            if isinstance(post, dict):\n",
    "                text = post.get('text', 'No text')[:100]\n",
    "                date = post.get('date', 'No date')\n",
    "                likes = post.get('likes', 'N/A')\n",
    "                print(f\"   ğŸ¦ Post {i+1}: {text}{'...' if len(post.get('text', '')) > 100 else ''}\")\n",
    "                print(f\"      ğŸ“… {date} | â¤ï¸ {likes}\")\n",
    "    \n",
    "    def _calculate_quality_score(self, data: List[Dict], analysis: Dict[str, Any]) -> float:\n",
    "        \"\"\"Calculate data quality score based on completeness and structure.\"\"\"\n",
    "        if not data:\n",
    "            return 0.0\n",
    "        \n",
    "        score = 0\n",
    "        max_score = 100\n",
    "        \n",
    "        # Basic data presence (40 points)\n",
    "        if len(data) > 0:\n",
    "            score += 20\n",
    "        if len(data) >= 5:\n",
    "            score += 20\n",
    "        \n",
    "        # Data structure quality (60 points)\n",
    "        if isinstance(data[0], dict):\n",
    "            # Check for key attributes\n",
    "            first_item = data[0]\n",
    "            \n",
    "            if 'profile' in first_item:\n",
    "                # Comprehensive data structure\n",
    "                profile = first_item['profile']\n",
    "                if profile.get('display_name'): score += 10\n",
    "                if profile.get('username'): score += 10\n",
    "                if profile.get('bio'): score += 5\n",
    "                if profile.get('followers_count') is not None: score += 10\n",
    "                \n",
    "                # Data types presence\n",
    "                if first_item.get('posts'): score += 15\n",
    "                if first_item.get('likes'): score += 5\n",
    "                if first_item.get('media'): score += 5\n",
    "                \n",
    "                # NEW: Check for reposts field (critical fix)\n",
    "                if 'reposts' in first_item: score += 10\n",
    "                else: score -= 20  # Penalty for missing reposts field\n",
    "                \n",
    "            else:\n",
    "                # Direct posts structure\n",
    "                posts_with_text = sum(1 for p in data if isinstance(p, dict) and p.get('text'))\n",
    "                if posts_with_text > 0: score += 25\n",
    "                if posts_with_text / len(data) > 0.8: score += 15\n",
    "                \n",
    "                posts_with_dates = sum(1 for p in data if isinstance(p, dict) and p.get('date'))\n",
    "                if posts_with_dates > 0: score += 10\n",
    "                \n",
    "                posts_with_metrics = sum(1 for p in data if isinstance(p, dict) and any(k in p for k in ['likes', 'retweets']))\n",
    "                if posts_with_metrics > 0: score += 10\n",
    "        \n",
    "        return min(score, max_score)\n",
    "    \n",
    "    def _get_emoji(self, data_type: str) -> str:\n",
    "        \"\"\"Get emoji for data type.\"\"\"\n",
    "        emojis = {\n",
    "            'posts': 'ğŸ“', 'likes': 'â¤ï¸', 'mentions': '@ï¸âƒ£', 'reposts': 'ğŸ”„',\n",
    "            'media': 'ğŸ–¼ï¸', 'followers': 'ğŸ‘¥', 'following': 'â¡ï¸'\n",
    "        }\n",
    "        return emojis.get(data_type, 'ğŸ“Š')\n",
    "    \n",
    "    def run_comprehensive_tests(self):\n",
    "        \"\"\"Run complete test suite.\"\"\"\n",
    "        print(\"ğŸ¦ TWITTER SCRAPER COMPREHENSIVE TEST SUITE\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"ğŸ“ API Endpoint: {EP}\")\n",
    "        print(f\"ğŸ“ Storage Path: {SCRAPED}\")\n",
    "        print(f\"ğŸ¯ Test Accounts: {list(TEST_ACCOUNTS.keys())}\")\n",
    "        print(f\"ğŸ”§ Test Configurations: {list(TEST_CONFIGS.keys())}\")\n",
    "        \n",
    "        # Check API connectivity\n",
    "        try:\n",
    "            test_response = requests.get(f\"{EP}/healthz\", timeout=5)\n",
    "            if test_response.status_code == 200:\n",
    "                print(f\"âœ… API connectivity: Connected to browser service\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ API connectivity: Unexpected response {test_response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ API connectivity: Failed - {e}\")\n",
    "            return\n",
    "        \n",
    "        # Test 1: Basic extraction across multiple accounts\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"ğŸ§ª TEST PHASE 1: BASIC EXTRACTION ACROSS ACCOUNTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        accounts_to_test = [\"naval\", \"paulg\", \"sama\"]\n",
    "        for account in accounts_to_test:\n",
    "            self.total_tests += 1\n",
    "            \n",
    "            payload = {\n",
    "                \"username\": account,\n",
    "                **TEST_CONFIGS[\"basic\"]\n",
    "            }\n",
    "            \n",
    "            test_name = f\"Basic Extraction - @{account}\"\n",
    "            result = self.submit_job(\"twitter\", payload, test_name)\n",
    "            \n",
    "            analysis = self.analyze_extraction_result(result, test_name)\n",
    "            self.results[test_name] = analysis\n",
    "            \n",
    "            if analysis[\"success\"]:\n",
    "                self.successful_tests += 1\n",
    "                if analysis[\"data_extracted\"]:\n",
    "                    self.data_quality_scores.append(analysis[\"quality_score\"])\n",
    "            else:\n",
    "                self.failed_tests += 1\n",
    "            \n",
    "            time.sleep(2)  # Brief pause between tests\n",
    "        \n",
    "        # Test 2: Level comparison on single account\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"ğŸ§ª TEST PHASE 2: SCRAPE LEVEL COMPARISON\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        test_account = \"vitalikbuterin\"\n",
    "        for level in [1, 2, 3, 4]:\n",
    "            self.total_tests += 1\n",
    "            \n",
    "            payload = {\n",
    "                \"username\": test_account,\n",
    "                \"scrape_posts\": True,\n",
    "                \"max_posts\": 8,\n",
    "                \"scrape_level\": level,\n",
    "                \"level\": level\n",
    "            }\n",
    "            \n",
    "            test_name = f\"Level {level} Extraction - @{test_account}\"\n",
    "            result = self.submit_job(\"twitter\", payload, test_name)\n",
    "            \n",
    "            analysis = self.analyze_extraction_result(result, test_name)\n",
    "            self.results[test_name] = analysis\n",
    "            \n",
    "            if analysis[\"success\"]:\n",
    "                self.successful_tests += 1\n",
    "                if analysis[\"data_extracted\"]:\n",
    "                    self.data_quality_scores.append(analysis[\"quality_score\"])\n",
    "            else:\n",
    "                self.failed_tests += 1\n",
    "        \n",
    "        # Test 3: Comprehensive extraction with all features\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"ğŸ§ª TEST PHASE 3: COMPREHENSIVE EXTRACTION\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        self.total_tests += 1\n",
    "        \n",
    "        payload = {\n",
    "            \"username\": \"naval\",\n",
    "            **TEST_CONFIGS[\"comprehensive\"]\n",
    "        }\n",
    "        \n",
    "        test_name = \"Comprehensive Extraction - @naval\"\n",
    "        result = self.submit_job(\"twitter\", payload, test_name)\n",
    "        \n",
    "        analysis = self.analyze_extraction_result(result, test_name)\n",
    "        self.results[test_name] = analysis\n",
    "        \n",
    "        if analysis[\"success\"]:\n",
    "            self.successful_tests += 1\n",
    "            if analysis[\"data_extracted\"]:\n",
    "                self.data_quality_scores.append(analysis[\"quality_score\"])\n",
    "        else:\n",
    "            self.failed_tests += 1\n",
    "        \n",
    "        # Test 4: Date filtering performance\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"ğŸ§ª TEST PHASE 4: DATE FILTERING PERFORMANCE\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        date_ranges = [\"last_day\", \"last_week\"]\n",
    "        for date_range in date_ranges:\n",
    "            self.total_tests += 1\n",
    "            \n",
    "            payload = {\n",
    "                \"username\": \"sama\",\n",
    "                \"scrape_posts\": True,\n",
    "                \"max_posts\": 15,\n",
    "                \"enable_date_filtering\": True,\n",
    "                \"date_range\": date_range,\n",
    "                \"scrape_level\": 4\n",
    "            }\n",
    "            \n",
    "            test_name = f\"Date Filter ({date_range}) - @sama\"\n",
    "            result = self.submit_job(\"twitter\", payload, test_name)\n",
    "            \n",
    "            analysis = self.analyze_extraction_result(result, test_name)\n",
    "            self.results[test_name] = analysis\n",
    "            \n",
    "            if analysis[\"success\"]:\n",
    "                self.successful_tests += 1\n",
    "                if analysis[\"data_extracted\"]:\n",
    "                    self.data_quality_scores.append(analysis[\"quality_score\"])\n",
    "            else:\n",
    "                self.failed_tests += 1\n",
    "        \n",
    "        # Generate final report\n",
    "        self.generate_final_report()\n",
    "    \n",
    "    def generate_final_report(self):\n",
    "        \"\"\"Generate comprehensive final report.\"\"\"\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"ğŸ“Š COMPREHENSIVE TEST RESULTS & ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Overall statistics\n",
    "        success_rate = (self.successful_tests / self.total_tests * 100) if self.total_tests > 0 else 0\n",
    "        avg_quality = sum(self.data_quality_scores) / len(self.data_quality_scores) if self.data_quality_scores else 0\n",
    "        \n",
    "        print(f\"ğŸ“ˆ OVERALL STATISTICS:\")\n",
    "        print(f\"   ğŸ¯ Total Tests: {self.total_tests}\")\n",
    "        print(f\"   âœ… Successful: {self.successful_tests} ({success_rate:.1f}%)\")\n",
    "        print(f\"   âŒ Failed: {self.failed_tests}\")\n",
    "        print(f\"   ğŸ“Š Tests with Data: {len(self.data_quality_scores)}\")\n",
    "        print(f\"   ğŸ† Average Quality Score: {avg_quality:.1f}%\")\n",
    "        \n",
    "        # Detailed results breakdown\n",
    "        print(f\"\\nğŸ“‹ DETAILED TEST RESULTS:\")\n",
    "        for test_name, analysis in self.results.items():\n",
    "            status = \"âœ…\" if analysis[\"success\"] else \"âŒ\"\n",
    "            data_status = f\"({analysis['total_items']} items)\" if analysis[\"data_extracted\"] else \"(no data)\"\n",
    "            quality = f\"Q:{analysis['quality_score']:.0f}%\" if analysis[\"quality_score\"] > 0 else \"Q:0%\"\n",
    "            \n",
    "            print(f\"   {status} {test_name}: {data_status} {quality}\")\n",
    "            \n",
    "            # Show issues if any\n",
    "            if analysis[\"issues\"]:\n",
    "                for issue in analysis[\"issues\"]:\n",
    "                    print(f\"      âš ï¸ {issue}\")\n",
    "        \n",
    "        # Data extraction analysis\n",
    "        tests_with_data = sum(1 for a in self.results.values() if a[\"data_extracted\"])\n",
    "        total_items_extracted = sum(a[\"total_items\"] for a in self.results.values())\n",
    "        \n",
    "        print(f\"\\nğŸ“Š DATA EXTRACTION ANALYSIS:\")\n",
    "        print(f\"   ğŸ“ˆ Tests with Data: {tests_with_data}/{self.total_tests} ({tests_with_data/self.total_tests*100:.1f}%)\")\n",
    "        print(f\"   ğŸ“Š Total Items Extracted: {total_items_extracted}\")\n",
    "        print(f\"   ğŸ“ˆ Average Items per Successful Test: {total_items_extracted/tests_with_data:.1f}\" if tests_with_data > 0 else \"   ğŸ“ˆ Average Items: 0\")\n",
    "        \n",
    "        # Data types breakdown\n",
    "        data_type_counts = {}\n",
    "        for analysis in self.results.values():\n",
    "            for data_type, count in analysis.get(\"data_types\", {}).items():\n",
    "                data_type_counts[data_type] = data_type_counts.get(data_type, 0) + count\n",
    "        \n",
    "        if data_type_counts:\n",
    "            print(f\"\\nğŸ“Š DATA TYPES EXTRACTED:\")\n",
    "            for data_type, count in sorted(data_type_counts.items()):\n",
    "                emoji = self._get_emoji(data_type)\n",
    "                print(f\"   {emoji} {data_type.title()}: {count} total items\")\n",
    "        \n",
    "        # CORE FIXES SUMMARY\n",
    "        print(f\"\\nğŸ”§ CORE FIXES SUMMARY:\")\n",
    "        reposts_tests = [a for a in self.results.values() if 'reposts' in a.get('data_types', {})]\n",
    "        reposts_working = len([a for a in reposts_tests if a['data_types'].get('reposts', -1) >= 0])\n",
    "        reposts_missing = len([a for a in self.results.values() if 'CRITICAL: reposts field missing' in ' '.join(a.get('issues', []))])\n",
    "        \n",
    "        print(f\"   ğŸ”„ Reposts field: {'âœ… FIXED' if reposts_missing == 0 else f'âŒ BROKEN ({reposts_missing} tests missing field)'}\")\n",
    "        print(f\"   ğŸ“Š Tests with reposts data: {reposts_working}/{len(reposts_tests) if reposts_tests else 0}\")\n",
    "        \n",
    "        # Performance assessment\n",
    "        print(f\"\\nğŸ¯ OVERALL ASSESSMENT:\")\n",
    "        if success_rate >= 90 and avg_quality >= 70:\n",
    "            print(f\"ğŸ‰ EXCELLENT - Twitter scraper is working perfectly!\")\n",
    "        elif success_rate >= 75 and avg_quality >= 50:\n",
    "            print(f\"âœ… GOOD - Twitter scraper is working well with minor issues\")\n",
    "        elif success_rate >= 50:\n",
    "            print(f\"âš ï¸ FAIR - Twitter scraper has issues that need attention\")\n",
    "        else:\n",
    "            print(f\"âŒ POOR - Twitter scraper needs significant fixes\")\n",
    "        \n",
    "        # Storage information\n",
    "        twitter_dir = SCRAPED / \"twitter\"\n",
    "        if twitter_dir.exists():\n",
    "            recent_jobs = sorted([d.name for d in twitter_dir.iterdir() if d.is_dir()], reverse=True)[:5]\n",
    "            print(f\"\\nğŸ“ RECENT JOB DATA:\")\n",
    "            for job_id in recent_jobs:\n",
    "                job_path = twitter_dir / job_id\n",
    "                files = list(job_path.glob(\"*\")) if job_path.exists() else []\n",
    "                print(f\"   ğŸ“‚ {job_id}: {len(files)} files\")\n",
    "        \n",
    "        print(f\"\\nğŸ”— Raw data files: {SCRAPED}/twitter/\")\n",
    "        print(f\"ğŸ‰ COMPREHENSIVE TESTING COMPLETED!\")\n",
    "\n",
    "# Initialize and run comprehensive test suite\n",
    "if __name__ == \"__main__\":\n",
    "    test_suite = TwitterTestSuite()\n",
    "    test_suite.run_comprehensive_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
